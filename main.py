"""
Daily arXiv Agent - ä¸»ç¨‹åºå…¥å£

æ¯æ—¥è¿½è¸ª arXiv æœ€æ–°è®ºæ–‡ï¼Œä½¿ç”¨ LLM è¿›è¡Œæ€»ç»“å’Œåˆ†æ
"""
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from src.utils import load_config, load_env, setup_logging, get_date_string


def main():
    """ä¸»å‡½æ•°"""
    # åŠ è½½é…ç½®
    load_env()
    config = load_config()
    logger = setup_logging(config)
    
    logger.info("=" * 60)
    logger.info("Daily arXiv Agent å¯åŠ¨")
    logger.info(f"æ—¥æœŸ: {get_date_string()}")
    logger.info("=" * 60)
    
    try:
        # ç¬¬äºŒæ­¥ - å®ç°è®ºæ–‡çˆ¬å– âœ…
        logger.info("æ­¥éª¤ 1: çˆ¬å– arXiv è®ºæ–‡...")
        from src.crawler.arxiv_fetcher import ArxivFetcher
        fetcher = ArxivFetcher(config)
        
        # å°è¯•è·å–è®ºæ–‡ï¼Œå¦‚æœæ²¡æ‰¾åˆ°ï¼Œé€æ­¥æ”¾å®½æ¡ä»¶
        papers = fetcher.fetch_papers(days_back=2)
        
        if not papers:
            logger.warning("âš ï¸  è¿‡å»2å¤©æ²¡æœ‰æ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„è®ºæ–‡ï¼Œå°è¯•æ‰©å¤§åˆ°7å¤©...")
            papers = fetcher.fetch_papers(days_back=7)
        
        if papers:
            fetcher.print_paper_summary(papers)
        else:
            logger.warning("âš ï¸  æ²¡æœ‰æ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„è®ºæ–‡")
            logger.info("ğŸ’¡ æç¤º: å¯ä»¥å°è¯•ä»¥ä¸‹æ–¹æ³•ï¼š")
            logger.info("   1. åœ¨ config.yaml ä¸­å¢åŠ  days_back æˆ– max_results")
            logger.info("   2. å‡å°‘æˆ–åˆ é™¤å…³é”®è¯è¿‡æ»¤ï¼ˆè®¾ç½® keywords: []ï¼‰")
            logger.info("   3. ä¿®æ”¹ç±»åˆ«èŒƒå›´")
            return
        
        # ç¬¬ä¸‰æ­¥ - å®ç°è®ºæ–‡æ€»ç»“ âœ…
        logger.info("\næ­¥éª¤ 2: æ€»ç»“è®ºæ–‡...")
        from src.summarizer.paper_summarizer import PaperSummarizer
        
        try:
            summarizer = PaperSummarizer(config)
            summarized_papers = summarizer.summarize_papers(papers)
            
            # ç”Ÿæˆæ¯æ—¥æŠ¥å‘Š
            logger.info("\nç”Ÿæˆæ¯æ—¥æŠ¥å‘Š...")
            report = summarizer.generate_daily_report(summarized_papers)
            
            # ä¿å­˜æŠ¥å‘Š
            report_path = f"data/summaries/report_{get_date_string()}.md"
            from pathlib import Path
            Path(report_path).parent.mkdir(parents=True, exist_ok=True)
            with open(report_path, 'w', encoding='utf-8') as f:
                f.write(report)
            logger.info(f"ğŸ“„ æ¯æ—¥æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_path}")
            
        except Exception as e:
            logger.error(f"è®ºæ–‡æ€»ç»“å¤±è´¥: {str(e)}")
            logger.info("ç»§ç»­æ‰§è¡Œåç»­æ­¥éª¤...")
            summarized_papers = papers
        
        # ç¬¬å››æ­¥ - å®ç°è¶‹åŠ¿åˆ†æ âœ…
        logger.info("\næ­¥éª¤ 3: åˆ†æç ”ç©¶è¶‹åŠ¿...")
        try:
            from src.analyzer.trend_analyzer import TrendAnalyzer
            from src.summarizer.llm_factory import LLMClientFactory
            
            # åˆ›å»º LLM å®¢æˆ·ç«¯ï¼ˆç”¨äºæ·±åº¦åˆ†æï¼‰
            llm_client = LLMClientFactory.create_client(config)
            
            # åŠ è½½è®ºæ–‡æ€»ç»“
            from src.utils import load_json
            summaries_data = load_json('data/summaries/latest.json')
            summaries = summaries_data.get('summaries', []) if summaries_data else []
            
            # åˆ›å»ºè¶‹åŠ¿åˆ†æå™¨
            analyzer = TrendAnalyzer(config, llm_client)
            analysis = analyzer.analyze(papers, summaries)
            
            if analysis:
                analyzer.print_analysis_summary(analysis)
            
        except Exception as e:
            logger.error(f"è¶‹åŠ¿åˆ†æå¤±è´¥: {str(e)}", exc_info=True)
            logger.info("ç»§ç»­æ‰§è¡Œåç»­æ­¥éª¤...")
        
        logger.info("=" * 60)
        logger.info("âœ… æ‰€æœ‰ä»»åŠ¡å®Œæˆï¼")
        logger.info("=" * 60)
        logger.info("æç¤º: è¿è¡Œ 'python src/web/app.py' å¯åŠ¨ Web æœåŠ¡æŸ¥çœ‹ç»“æœ")
        
    except Exception as e:
        logger.error(f"âŒ æ‰§è¡Œå‡ºé”™: {str(e)}", exc_info=True)
        sys.exit(1)


if __name__ == "__main__":
    main()
