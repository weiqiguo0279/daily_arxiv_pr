# LLM è®ºæ–‡æ€»ç»“æ¨¡å—ä½¿ç”¨æŒ‡å—

## ğŸ“– æ¨¡å—ä»‹ç»

è®ºæ–‡æ€»ç»“æ¨¡å—ä½¿ç”¨å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰è‡ªåŠ¨æ€»ç»“ arXiv è®ºæ–‡ï¼Œæ”¯æŒå¤šä¸ªä¸»æµ LLM æä¾›å•†ã€‚

## ğŸ¤– æ”¯æŒçš„ LLM æä¾›å•†

| æä¾›å•† | è¯´æ˜ | æ¨èæ¨¡å‹ |
|-------|------|---------|
| **OpenAI** | GPT ç³»åˆ—ï¼Œè´¨é‡æœ€é«˜ | gpt-4o-mini, gpt-4o |
| **Google Gemini** | æ€§ä»·æ¯”é«˜ï¼Œé€Ÿåº¦å¿« | gemini-1.5-flash |
| **Anthropic Claude** | é•¿æ–‡æœ¬èƒ½åŠ›å¼º | claude-3-5-sonnet |
| **DeepSeek** | å›½äº§ï¼Œä»·æ ¼ä¾¿å®œ | deepseek-chat |
| **vLLM** | æœ¬åœ°éƒ¨ç½²ï¼Œå®Œå…¨å…è´¹ | è‡ªå®šä¹‰æ¨¡å‹ |

## âš™ï¸ é…ç½®è¯´æ˜

### 1. é€‰æ‹© LLM æä¾›å•†

åœ¨ `config/config.yaml` ä¸­è®¾ç½®ï¼š

```yaml
llm:
  provider: "openai"  # å¯é€‰: openai, gemini, claude, deepseek, vllm
```

### 2. é…ç½® API Key

åœ¨ `.env` æ–‡ä»¶ä¸­è®¾ç½®å¯¹åº”çš„ API Keyï¼š

```bash
# OpenAI
OPENAI_API_KEY=sk-...

# Google Gemini
GEMINI_API_KEY=...

# Anthropic Claude
CLAUDE_API_KEY=sk-ant-...

# DeepSeek
DEEPSEEK_API_KEY=sk-...

# vLLM (æœ¬åœ°éƒ¨ç½²)
VLLM_BASE_URL=http://localhost:8000/v1
VLLM_MODEL=your-model-name
```

### 3. è¯¦ç»†é…ç½®é€‰é¡¹

```yaml
llm:
  provider: "openai"
  
  openai:
    api_key: ""  # ç•™ç©ºï¼Œä» .env è¯»å–
    model: "gpt-4o-mini"
    base_url: ""  # å¯é€‰ï¼Œç”¨äºä»£ç†
    temperature: 0.7
    max_tokens: 1500
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### æ–¹æ¡ˆ 1: OpenAI (æ¨è)

1. **è·å– API Key**
   - è®¿é—®: https://platform.openai.com/api-keys
   - åˆ›å»ºæ–°çš„ API Key

2. **é…ç½®**
   ```yaml
   # config/config.yaml
   llm:
     provider: "openai"
     openai:
       model: "gpt-4o-mini"  # ä¾¿å®œå¿«é€Ÿ
       temperature: 0.7
       max_tokens: 1500
   ```
   
   ```bash
   # .env
   OPENAI_API_KEY=sk-your-key-here
   ```

3. **è¿è¡Œ**
   ```bash
   python main.py
   ```

### æ–¹æ¡ˆ 2: Google Gemini (å…è´¹é¢åº¦å¤§)

1. **è·å– API Key**
   - è®¿é—®: https://makersuite.google.com/app/apikey
   - åˆ›å»º API Key

2. **é…ç½®**
   ```yaml
   # config/config.yaml
   llm:
     provider: "gemini"
     gemini:
       model: "gemini-1.5-flash"
       temperature: 0.7
       max_tokens: 1500
   ```
   
   ```bash
   # .env
   GEMINI_API_KEY=your-key-here
   ```

### æ–¹æ¡ˆ 3: Claude

1. **è·å– API Key**
   - è®¿é—®: https://console.anthropic.com/
   - åˆ›å»º API Key

2. **é…ç½®**
   ```yaml
   llm:
     provider: "claude"
     claude:
       model: "claude-3-5-sonnet-20241022"
       temperature: 0.7
   ```
   
   ```bash
   # .env
   CLAUDE_API_KEY=sk-ant-your-key-here
   ```

### æ–¹æ¡ˆ 4: DeepSeek (å›½äº§)

1. **è·å– API Key**
   - è®¿é—®: https://platform.deepseek.com/
   - æ³¨å†Œå¹¶åˆ›å»º API Key

2. **é…ç½®**
   ```yaml
   llm:
     provider: "deepseek"
     deepseek:
       model: "deepseek-chat"
       base_url: "https://api.deepseek.com/v1"
   ```
   
   ```bash
   # .env
   DEEPSEEK_API_KEY=sk-your-key-here
   ```

### æ–¹æ¡ˆ 5: vLLM (æœ¬åœ°éƒ¨ç½²)

1. **å¯åŠ¨ vLLM æœåŠ¡**
   ```bash
   python -m vllm.entrypoints.openai.api_server \
     --model meta-llama/Llama-2-7b-chat-hf \
     --port 8000
   ```

2. **é…ç½®**
   ```yaml
   llm:
     provider: "vllm"
     vllm:
       model: "meta-llama/Llama-2-7b-chat-hf"
       base_url: "http://localhost:8000/v1"
       api_key: "EMPTY"
   ```

## ğŸ“Š åŠŸèƒ½ç‰¹æ€§

### 1. å•ç¯‡è®ºæ–‡æ€»ç»“

```python
from src.summarizer.paper_summarizer import PaperSummarizer

summarizer = PaperSummarizer(config)
summarized_paper = summarizer.summarize_paper(paper)

print(summarized_paper['summary'])
```

### 2. æ‰¹é‡è®ºæ–‡æ€»ç»“

```python
summarized_papers = summarizer.summarize_papers(papers)
```

### 3. ç”Ÿæˆæ¯æ—¥æŠ¥å‘Š

```python
report = summarizer.generate_daily_report(summarized_papers)
print(report)  # Markdown æ ¼å¼çš„æŠ¥å‘Š
```

## ğŸ§ª æµ‹è¯•

```bash
# æµ‹è¯• LLM è¿æ¥å’ŒåŠŸèƒ½
python test_summarizer.py
```

æµ‹è¯•è„šæœ¬ä¼šï¼š
1. æµ‹è¯• LLM å®¢æˆ·ç«¯åˆ›å»º
2. æµ‹è¯•ç®€å•æ–‡æœ¬ç”Ÿæˆ
3. æµ‹è¯•è®ºæ–‡æ€»ç»“åŠŸèƒ½
4. ï¼ˆå¯é€‰ï¼‰å¯¹æ¯”ä¸åŒ LLM æä¾›å•†

## ğŸ’° æˆæœ¬å¯¹æ¯”

| æä¾›å•† | è¾“å…¥ä»·æ ¼ | è¾“å‡ºä»·æ ¼ | å¤‡æ³¨ |
|-------|---------|---------|------|
| OpenAI gpt-4o-mini | $0.15/1M tokens | $0.6/1M tokens | æ€§ä»·æ¯”æœ€é«˜ |
| Gemini Flash | å…è´¹ | å…è´¹ | æœ‰é…é¢é™åˆ¶ |
| Claude Sonnet | $3/1M tokens | $15/1M tokens | è´¨é‡å¾ˆé«˜ |
| DeepSeek | Â¥1/1M tokens | Â¥2/1M tokens | éå¸¸ä¾¿å®œ |
| vLLM | å…è´¹ | å…è´¹ | éœ€è¦ GPU |

**ä¼°ç®—**: æ€»ç»“ 20 ç¯‡è®ºæ–‡çº¦æ¶ˆè€— ~30K tokensï¼Œæˆæœ¬ï¼š
- OpenAI gpt-4o-mini: ~$0.02
- Gemini: å…è´¹
- DeepSeek: ~Â¥0.06
- vLLM: å…è´¹

## ğŸ”§ é«˜çº§é…ç½®

### è‡ªå®šä¹‰æç¤ºè¯

ä¿®æ”¹ `src/summarizer/paper_summarizer.py`ï¼š

```python
SYSTEM_PROMPT = """ä½ çš„è‡ªå®šä¹‰ç³»ç»Ÿæç¤ºè¯..."""

USER_PROMPT_TEMPLATE = """ä½ çš„è‡ªå®šä¹‰ç”¨æˆ·æç¤ºè¯...
æ ‡é¢˜ï¼š{title}
..."""
```

### è°ƒæ•´ç”Ÿæˆå‚æ•°

```yaml
llm:
  openai:
    temperature: 0.5  # é™ä½éšæœºæ€§ï¼Œæ›´ç¡®å®šçš„è¾“å‡º
    max_tokens: 2000  # å¢åŠ è¾“å‡ºé•¿åº¦
```

### ä½¿ç”¨ä»£ç†

```yaml
llm:
  openai:
    base_url: "https://your-proxy.com/v1"
```

æˆ–åœ¨ `.env` ä¸­ï¼š
```bash
OPENAI_BASE_URL=https://your-proxy.com/v1
```

## ğŸ“ è¾“å‡ºæ ¼å¼

### æ€»ç»“æ•°æ®

ä¿å­˜åœ¨ `data/summaries/summaries_YYYY-MM-DD.json`ï¼š

```json
{
  "id": "2310.12345",
  "title": "è®ºæ–‡æ ‡é¢˜",
  "summary": "è¿™æ˜¯ä¸€ç¯‡å…³äº...çš„è®ºæ–‡ï¼Œä¸»è¦åˆ›æ–°ç‚¹æ˜¯...",
  "summarized_at": "2024-10-13T10:30:00",
  ...
}
```

### æ¯æ—¥æŠ¥å‘Š

ä¿å­˜åœ¨ `data/summaries/report_YYYY-MM-DD.md`ï¼ŒMarkdown æ ¼å¼ã€‚

## ğŸ› å¸¸è§é—®é¢˜

### Q1: API Key é”™è¯¯

**é”™è¯¯ä¿¡æ¯**: `ValueError: XXX API Key æœªè®¾ç½®`

**è§£å†³æ–¹æ³•**:
```bash
# 1. æ£€æŸ¥ .env æ–‡ä»¶
cat .env

# 2. ç¡®è®¤ API Key æ ¼å¼æ­£ç¡®
# OpenAI: sk-...
# Claude: sk-ant-...
# Gemini: AI...

# 3. é‡æ–°åŠ è½½ç¯å¢ƒå˜é‡
source .env  # æˆ–é‡å¯ç¨‹åº
```

### Q2: é€Ÿç‡é™åˆ¶

**é”™è¯¯ä¿¡æ¯**: `Rate limit exceeded`

**è§£å†³æ–¹æ³•**:
- é™ä½å¹¶å‘æ•°ï¼ˆç›®å‰æ˜¯é¡ºåºå¤„ç†ï¼‰
- å‡çº§ API å¥—é¤
- åˆ‡æ¢åˆ°å…¶ä»–æä¾›å•†
- ä½¿ç”¨æœ¬åœ° vLLM

### Q3: è¿æ¥è¶…æ—¶

**é”™è¯¯ä¿¡æ¯**: `Connection timeout`

**è§£å†³æ–¹æ³•**:
- æ£€æŸ¥ç½‘ç»œè¿æ¥
- ä½¿ç”¨ä»£ç†
- åˆ‡æ¢æä¾›å•†

### Q4: vLLM è¿æ¥å¤±è´¥

**é”™è¯¯ä¿¡æ¯**: `Failed to connect to vLLM`

**è§£å†³æ–¹æ³•**:
```bash
# 1. ç¡®è®¤ vLLM æœåŠ¡æ­£åœ¨è¿è¡Œ
curl http://localhost:8000/v1/models

# 2. æ£€æŸ¥é…ç½®
# config.yaml ä¸­çš„ base_url æ˜¯å¦æ­£ç¡®

# 3. æŸ¥çœ‹ vLLM æ—¥å¿—
```

### Q5: ä¸­æ–‡ä¹±ç 

**è§£å†³æ–¹æ³•**:
- ç¡®ä¿æ–‡ä»¶ä»¥ UTF-8 ç¼–ç ä¿å­˜
- æ£€æŸ¥ç»ˆç«¯ç¼–ç è®¾ç½®

## ğŸ¯ æœ€ä½³å®è·µ

### 1. é€‰æ‹©åˆé€‚çš„æ¨¡å‹

- **å¿«é€ŸåŸå‹**: gemini-1.5-flash (å…è´¹)
- **æ—¥å¸¸ä½¿ç”¨**: gpt-4o-mini (ä¾¿å®œ)
- **é«˜è´¨é‡**: claude-3-5-sonnet
- **å›½å†…ç½‘ç»œ**: deepseek-chat
- **éšç§ä¼˜å…ˆ**: vLLM (æœ¬åœ°)

### 2. ä¼˜åŒ–æˆæœ¬

```python
# åªæ€»ç»“é‡è¦è®ºæ–‡
important_papers = [p for p in papers if is_important(p)]
summarized = summarizer.summarize_papers(important_papers)

# æˆ–è€…ä½¿ç”¨æ›´ä¾¿å®œçš„æ¨¡å‹
config['llm']['provider'] = 'gemini'
```

### 3. é”™è¯¯å¤„ç†

ç¨‹åºå·²å†…ç½®é”™è¯¯å¤„ç†ï¼Œå¤±è´¥çš„è®ºæ–‡ä¼šæ ‡è®° `summary_error=True`ã€‚

## ğŸ“š ç›¸å…³æ–‡æ¡£

- [OpenAI API æ–‡æ¡£](https://platform.openai.com/docs/api-reference)
- [Google Gemini æ–‡æ¡£](https://ai.google.dev/docs)
- [Anthropic Claude æ–‡æ¡£](https://docs.anthropic.com/)
- [DeepSeek æ–‡æ¡£](https://platform.deepseek.com/api-docs/)
- [vLLM æ–‡æ¡£](https://docs.vllm.ai/)
