# 📚 每日 arXiv 论文总结

**日期**: 2026-01-09
**论文数量**: 5 篇
**LLM**: DeepSeek (deepseek-chat)

---


## 1. ContextFocus: Activation Steering for Contextual Faithfulness in Large Language Models

**作者**: Nikhil Anand, Shwetha Somasundaram, Anirudh Phukan et al.

**类别**: cs.CL, cs.AI, cs.LG

**链接**: [2601.04131v1](https://arxiv.org/pdf/2601.04131v1)

**总结**:
本文提出了一种名为ContextFocus的轻量级激活引导方法，旨在提升大语言模型在知识冲突场景下的上下文忠实性。该方法无需微调模型，通过干预模型内部激活来引导模型优先遵循外部检索的上下文证据，而非依赖内部记忆知识，从而显著减少不忠实输出。实验表明，ContextFocus在ConFiQA基准测试中优于多种基线方法，且与提示策略互补，在更大模型上仍保持高效和鲁棒性。

---


## 2. FOREVER: Forgetting Curve-Inspired Memory Replay for Language Model Continual Learning

**作者**: Yujie Feng, Hao Wang, Jian Li et al.

**类别**: cs.LG, cs.AI, cs.CL

**链接**: [2601.03938v1](https://arxiv.org/pdf/2601.03938v1)

**总结**:
本文提出FOREVER框架，旨在解决大语言模型持续学习中的灾难性遗忘问题。其核心创新在于借鉴艾宾浩斯遗忘曲线，提出以模型优化器更新幅度定义的“模型时间”来替代传统固定步长的回放调度，使回放时机更贴合模型内部学习动态。该方法结合基于遗忘曲线的回放调度器和强度感知正则化机制，在多个基准测试和不同规模模型（0.6B-13B参数）上均有效缓解了遗忘，实现了更符合学习进程的持续知识获取。

---


## 3. Adaptive-Boundary-Clipping GRPO: Ensuring Bounded Ratios for Stable and Generalizable Training

**作者**: Chi Liu, Xin Chen

**类别**: cs.LG, cs.AI, cs.CL

**链接**: [2601.03895v1](https://arxiv.org/pdf/2601.03895v1)

**总结**:
本文提出了一种改进的强化学习算法——自适应边界裁剪GRPO（ABC-GRPO），用于提升大语言模型在策略优化中的训练稳定性和泛化能力。该方法针对原始GRPO算法中裁剪机制的局限性，引入了非对称且自适应的边界调整策略，从而在数学推理任务上显著超越了标准GRPO的表现。实验表明，ABC-GRPO在训练过程中能保持更高的策略熵，有效维持模型的探索能力并避免早熟收敛，增强了算法的灵活性与泛化性。

---


## 4. From Brute Force to Semantic Insight: Performance-Guided Data Transformation Design with LLMs

**作者**: Usha Shrestha, Dmitry Ignatov, Radu Timofte

**类别**: cs.CV, cs.LG

**链接**: [2601.03808v1](https://arxiv.org/pdf/2601.03808v1)

**总结**:
本文提出了一种基于性能反馈的闭环方法，使大语言模型能够自主设计最优的数据增强变换。该方法通过在包含6000多个经验评估的PyTorch增强函数库上进行低秩适应微调，仅依据下游模型准确率进行标注，并利用成对性能排序进行训练，无需强化学习或奖励模型。实验表明，该方法相比暴力搜索可减少高达600倍的候选评估量，同时保持竞争力的峰值准确率，且模型能够内化语义性能线索而非记忆语法，实现了从随机合成到任务对齐设计的转变。

---


## 5. EDCO: Dynamic Curriculum Orchestration for Domain-specific Large Language Model Fine-tuning

**作者**: Jing-Cheng Pang, Liu Sun, Chang Zhou et al.

**类别**: cs.LG

**链接**: [2601.03725v1](https://arxiv.org/pdf/2601.03725v1)

**总结**:
本文提出EDCO框架，通过动态课程编排优化领域大语言模型的微调过程。其核心创新在于引入推理熵作为样本选择标准，并设计高效熵估计器、基于熵的课程生成器和模型训练器三个组件，实现根据模型学习状态实时调整训练样本顺序。实验表明，EDCO在通信、医疗和法律领域的微调任务中均优于静态课程学习方法，且高效熵估计方法在保持精度的同时将计算时间降低了83.5%。

---
