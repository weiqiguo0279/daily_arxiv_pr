# 📚 每日 arXiv 论文总结

**日期**: 2026-01-09
**论文数量**: 5 篇
**LLM**: DeepSeek (deepseek-chat)

---


## 1. Agent Drift: Quantifying Behavioral Degradation in Multi-Agent LLM Systems Over Extended Interactions

**作者**: Abhishek Rath

**类别**: cs.AI

**链接**: [2601.04170v1](https://arxiv.org/pdf/2601.04170v1)

**总结**:
本研究提出了“智能体漂移”概念，指多智能体大语言模型系统在长期交互中行为、决策质量和协作一致性的逐步退化。论文构建了理论框架，将漂移分为语义、协调和行为三种表现，并设计了包含12个维度的智能体稳定性指数（ASI）进行量化评估。研究进一步提出基于情景记忆、漂移感知路由和自适应行为锚定的缓解策略，为提升生产级AI系统的长期稳定性和部署可靠性提供了方法论基础。

---


## 2. Diffusion-DRF: Differentiable Reward Flow for Video Diffusion Fine-Tuning

**作者**: Yifan Wang, Yanyu Li, Sergey Tulyakov et al.

**类别**: cs.CV

**链接**: [2601.04153v1](https://arxiv.org/pdf/2601.04153v1)

**总结**:
本文提出Diffusion-DRF，一种用于视频扩散模型微调的可微分奖励流方法。其核心创新在于利用冻结的视觉语言模型（VLM）作为无需训练的评判器，通过反向传播将VLM的反馈直接融入去噪链中，从而生成面向令牌的梯度以优化模型。该方法设计了自动化、多维度结构的提示流程来获取可靠的VLM反馈，并通过梯度检查点技术实现高效更新，有效提升了视频生成的质量与语义对齐，同时避免了奖励破解和训练不稳定的问题。Diffusion-DRF无需额外奖励模型或偏好数据，且可推广至其他基于扩散的生成任务。

---


## 3. ContextFocus: Activation Steering for Contextual Faithfulness in Large Language Models

**作者**: Nikhil Anand, Shwetha Somasundaram, Anirudh Phukan et al.

**类别**: cs.CL, cs.AI, cs.LG

**链接**: [2601.04131v1](https://arxiv.org/pdf/2601.04131v1)

**总结**:
本文提出了一种名为ContextFocus的轻量级激活引导方法，旨在提升大语言模型在知识冲突场景下对外部检索上下文的忠实遵循能力。该方法无需微调模型，仅需极小的推理开销，即可有效抑制模型对内部记忆知识的过度依赖，从而生成更忠实于给定上下文的输出，同时保持回答的流畅性。实验表明，该方法在ConFiQA基准测试中显著优于现有基线，且能与提示策略互补，在更大模型上依然有效，兼具高效性与鲁棒性。

---


## 4. InfiniteWeb: Scalable Web Environment Synthesis for GUI Agent Training

**作者**: Ziyun Zhang, Zezhou Wang, Xiaoyi Zhang et al.

**类别**: cs.CL, cs.AI, cs.CV

**链接**: [2601.04126v1](https://arxiv.org/pdf/2601.04126v1)

**总结**:
本文提出InfiniteWeb系统，用于大规模自动生成功能性网页环境以训练GUI智能体。该系统通过统一规范、任务驱动的测试开发，结合网站种子和参考设计图像，解决了构建多页面互联网站的现实性挑战，并生成可验证的任务评估器以提供强化学习的密集奖励信号。实验表明，InfiniteWeb在构建真实网站方面优于商业编码智能体，且在其生成环境中训练的GUI智能体在OSWorld和Online-Mind2Web基准测试中性能显著提升，验证了该系统的有效性。

---


## 5. GeoReason: Aligning Thinking And Answering In Remote Sensing Vision-Language Models Via Logical Consistency Reinforcement Learning

**作者**: Wenshuai Li, Xiantai Xiang, Zixiao Wen et al.

**类别**: cs.CV

**链接**: [2601.04118v1](https://arxiv.org/pdf/2601.04118v1)

**总结**:
本文提出GeoReason框架，旨在解决遥感视觉语言模型（RS-VLM）在空间推理任务中存在的逻辑幻觉问题，即模型可能基于错误推理链或位置捷径得出正确答案。该框架首先构建了包含4000条逻辑轨迹的GeoReason-Bench数据集，并通过两阶段训练策略：监督知识初始化使模型掌握推理语法与领域知识，以及一致性感知强化学习（引入逻辑一致性奖励机制）来强化推理的逻辑可靠性。实验表明，该方法显著提升了RS-VLM的认知可靠性与可解释性，在高级空间推理任务上达到了先进水平。

---
