# ğŸ“š æ¯æ—¥ arXiv è®ºæ–‡æ€»ç»“

**æ—¥æœŸ**: 2026-01-09
**è®ºæ–‡æ•°é‡**: 2 ç¯‡
**LLM**: DeepSeek (deepseek-chat)

---


 [2601.04170v1](https://arxiv.org/pdf/2601.04170v1)

**æ€»ç»“**:
- [Agent Drift: Quantifying Behavioral Degradation in Multi-Agent LLM Systems Over Extended Interactions](https://arxiv.org/abs/2601.04170)
  - Abhishek Rath
  - Publish Date: 2026.01.07
  - Task: Reasoning
  - Summaryï¼š
    - Introduces the concept of agent drift, defined as the progressive degradation of agent behavior, decision quality, and inter-agent coherence over extended interaction sequences in multi-agent LLM systems.
    - Proposes a theoretical framework with three drift manifestations (semantic, coordination, behavioral) and introduces the Agent Stability Index (ASI), a novel composite metric for quantifying drift across twelve dimensions.
    - Demonstrates how unchecked drift reduces task accuracy and proposes mitigation strategies (episodic memory consolidation, drift-aware routing, adaptive behavioral anchoring) to reduce errors and maintain system reliability.

---


 [2601.04131v1](https://arxiv.org/pdf/2601.04131v1)

**æ€»ç»“**:
- [ContextFocus: Activation Steering for Contextual Faithfulness in Large Language Models](https://arxiv.org/abs/2601.04131)
  - Nikhil Anand, Shwetha Somasundaram, Anirudh Phukan, Apoorv Saxena, Koyel Mukherjee
  - Publisher: (Inferred from authors/categories)
  - Publish Date: 2026.01.07
  - Task: Reasoning
  - Summaryï¼š
    - ContextFocus, a lightweight activation steering approach that improves context faithfulness in knowledge-conflict settings while preserving fluency and efficiency.
    - The method requires no model finetuning and incurs minimal inference-time overhead, making it highly efficient.
    - Evaluated on the ConFiQA benchmark, it shows significant improvements in contextual-faithfulness and is complementary to prompting strategies.

---
