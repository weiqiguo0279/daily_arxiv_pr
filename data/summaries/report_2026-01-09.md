# 📚 每日 arXiv 论文总结

**日期**: 2026-01-09
**论文数量**: 5 篇
**LLM**: DeepSeek (deepseek-chat)

---


## 1. Agent Drift: Quantifying Behavioral Degradation in Multi-Agent LLM Systems Over Extended Interactions

**作者**: Abhishek Rath

**类别**: cs.AI

**链接**: [2601.04170v1](https://arxiv.org/pdf/2601.04170v1)

**总结**:
本研究提出了“智能体漂移”概念，用于描述多智能体大语言模型系统在长期交互中行为、决策质量和协作一致性的渐进性退化。论文构建了包含语义漂移、协调漂移和行为漂移的理论框架，并设计了综合度量指标（Agent Stability Index）从12个维度量化漂移现象。作者进一步提出了基于情景记忆、漂移感知路由和自适应行为锚定的缓解策略，为提升生产级AI系统的长期稳定性和可靠性提供了方法论基础。

---


## 2. Diffusion-DRF: Differentiable Reward Flow for Video Diffusion Fine-Tuning

**作者**: Yifan Wang, Yanyu Li, Sergey Tulyakov et al.

**类别**: cs.CV

**链接**: [2601.04153v1](https://arxiv.org/pdf/2601.04153v1)

**总结**:
本文提出Diffusion-DRF方法，通过引入可微分的奖励流来优化视频扩散模型的微调过程。其主要创新在于利用冻结的视觉语言模型（VLM）作为无需训练的评估器，直接通过扩散去噪链反向传播VLM的反馈信号，将逻辑响应转化为面向标记的梯度进行优化。该方法避免了传统偏好优化对人工标注或可学习奖励模型的依赖，从而减少了训练偏差和奖励攻击问题，在提升视频生成质量和语义对齐的同时，实现了稳定高效的模型更新，并可推广至其他基于扩散的生成任务。

---


## 3. ContextFocus: Activation Steering for Contextual Faithfulness in Large Language Models

**作者**: Nikhil Anand, Shwetha Somasundaram, Anirudh Phukan et al.

**类别**: cs.CL, cs.AI, cs.LG

**链接**: [2601.04131v1](https://arxiv.org/pdf/2601.04131v1)

**总结**:
本文提出ContextFocus，一种轻量级的激活引导方法，旨在提升大语言模型在知识冲突场景下对外部检索上下文的忠实性。该方法无需微调模型，仅需极低的推理开销，即可有效抑制模型对内部记忆知识的依赖，从而生成更忠实于给定上下文的输出，同时保持回答的流畅性。实验表明，该方法在ConFiQA基准测试中显著优于现有基线，且与提示策略互补，在更大模型上同样有效，兼具高效性与鲁棒性。

---


## 4. InfiniteWeb: Scalable Web Environment Synthesis for GUI Agent Training

**作者**: Ziyun Zhang, Zezhou Wang, Xiaoyi Zhang et al.

**类别**: cs.CL, cs.AI, cs.CV

**链接**: [2601.04126v1](https://arxiv.org/pdf/2601.04126v1)

**总结**:
本文提出了InfiniteWeb系统，旨在解决GUI智能体训练中网络环境稀缺的问题。该系统通过统一规范、任务驱动的测试开发方法，结合网站种子和参考设计图像，实现了大规模、功能完整且多样化的网页环境自动生成。其主要创新在于能够构建多页面互联的真实网站，并生成可验证的任务评估器，为强化学习提供密集奖励信号。实验表明，InfiniteWeb在网站构建效果上优于商业编码智能体，基于其生成环境训练的GUI智能体在OSWorld和Online-Mind2Web基准测试中性能显著提升。

---


## 5. GeoReason: Aligning Thinking And Answering In Remote Sensing Vision-Language Models Via Logical Consistency Reinforcement Learning

**作者**: Wenshuai Li, Xiantai Xiang, Zixiao Wen et al.

**类别**: cs.CV

**链接**: [2601.04118v1](https://arxiv.org/pdf/2601.04118v1)

**总结**:
本文提出了GeoReason框架，旨在解决遥感视觉语言模型（RS-VLM）中存在的逻辑幻觉问题，即模型可能基于错误推理链或位置捷径得出正确答案。该框架通过构建逻辑驱动的数据集GeoReason-Bench，并采用两阶段训练策略：首先进行监督知识初始化以学习推理语法和领域知识，随后通过一致性感知强化学习（引入逻辑一致性奖励）来优化推理可靠性，从而确保内部思维过程与最终决策的逻辑一致。实验表明，该方法显著提升了RS-VLM的认知可靠性和可解释性，在复杂空间推理任务上达到了先进水平。

---
