# üìö ÊØèÊó• arXiv ËÆ∫ÊñáÊÄªÁªì

**Êó•Êúü**: 2026-01-09
**ËÆ∫ÊñáÊï∞Èáè**: 30 ÁØá
**LLM**: DeepSeek (deepseek-chat)

---


**ÊÄªÁªì**:
- [Towards Safe Autonomous Driving: A Real-Time Motion Planning Algorithm on Embedded Hardware](https://arxiv.org/abs/2601.03904)
  - Korbinian Moller, Glenn Johannes Tungka, Lucas J√ºrgens, Johannes Betz
  - Publisher: TUM-AVS
  - Publish Date: 2026.01.07
  - Code: [real-time-motion-planning](https://github.com/TUM-AVS/real-time-motion-planning)
  - Task: Planning
  - SummaryÔºö
    - Presents a lightweight sampling-based trajectory planner deployed on an automotive-grade embedded platform with a Real-Time Operating System (RTOS) for fail-operational autonomous driving.
    - Demonstrates deterministic timing with bounded latency and minimal jitter, validating the feasibility of trajectory planning on safety-certifiable hardware as an active safety extension.
    - Forms a foundation for future emergency planning architectures, highlighting the potential and challenges of integrating active fallback mechanisms into next-generation safeguarding frameworks.

---


**ÊÄªÁªì**:
- [A Vision-Language-Action Model with Visual Prompt for OFF-Road Autonomous Driving](https://arxiv.org/abs/2601.03519)
  - Liangdong Zhang, Yiming Nie, Haoyang Li, Fanjie Kong, Baobao Zhang, Shunxin Huang, Kai Fu, Chen Min, Liang Xiao
  - Publish Date: 2026.01.07
  - Task: Planning
  - Datasets: [RELLIS-3D](https://github.com/unmannedlab/RELLIS-3D)
  - SummaryÔºö
    - Proposes OFF-EMMA, an end-to-end multimodal framework for off-road autonomous driving, addressing insufficient spatial perception and unstable reasoning in VLA models.
    - Introduces a visual prompt block using semantic segmentation masks to enhance spatial understanding and a chain-of-thought with self-consistency (COT-SC) reasoning strategy to improve planning robustness.

---


**ÊÄªÁªì**:
- [FROST-Drive: Scalable and Efficient End-to-End Driving with a Frozen Vision Encoder](https://arxiv.org/abs/2601.03460)
  - Zeyu Dong, Yimin Zhu, Yu Wu, Yu Sun
  - Publish Date: 2026.01.06
  - Task: End-to-End
  - Datasets: [Waymo Open E2E Dataset](https://waymo.com/open/)
  - SummaryÔºö
    - FROST-Drive, a novel End-to-End (E2E) architecture that preserves the generalization capabilities of a pretrained Vision-Language Model (VLM) by keeping its vision encoder frozen.
    - The model combines the frozen encoder with a transformer-based adapter for multimodal fusion and a GRU-based decoder for waypoint generation, optimized with a custom loss for Rater Feedback Score (RFS).

---


**ÊÄªÁªì**:
- [Towards Efficient 3D Object Detection for Vehicle-Infrastructure Collaboration via Risk-Intent Selection](https://arxiv.org/abs/2601.03001)
  - Li Wang, Boqi Li, Hang Chen, Xingjian Wu, Yichen Wang, Jiewen Tan, Xinyu Zhang, Huaping Liu
  - Publish Date: 2026.01.06
  - Task: Detection
  - Datasets: [DeepAccident](https://github.com/DeepAccident/DeepAccident)
  - SummaryÔºö
    - Proposes Risk-intent Selective detection (RiSe), an interaction-aware framework for Vehicle-Infrastructure Collaborative Perception (VICP) that prioritizes the transmission of features from risk-critical regions over visible ones.
    - Introduces a Potential Field-Trajectory Correlation Model (PTCM) to assess kinematic risks and an Intention-Driven Area Prediction Module (IDAPM) to predict key Bird's-Eye-View areas for decision-making.
    - Achieves state-of-the-art detection accuracy while reducing communication volume to 0.71% of full feature sharing, establishing an efficient Pareto frontier between bandwidth and perception performance.

---


**ÊÄªÁªì**:
- [HOLO: Homography-Guided Pose Estimator Network for Fine-Grained Visual Localization on SD Maps](https://arxiv.org/abs/2601.02730)
  - Xuchang Zhong, Xu Cao, Jinke Feng, Hao Fang
  - Publish Date: 2026.01.06
  - Task: Perception
  - Datasets: [nuScenes](https://www.nuscenes.org/)
  - SummaryÔºö
    - Proposes a novel homography-guided pose estimator network for fine-grained visual localization between multi-view images and standard-definition (SD) maps.
    - Unifies BEV semantic reasoning with homography learning for image-to-map localization, improving training efficiency and accuracy over attention-based fusion and direct regression.
    - The framework supports cross-resolution inputs by explicitly modeling homography transformations, and demonstrates state-of-the-art performance on nuScenes.

---


**ÊÄªÁªì**:
- [VIT-Ped: Visionary Intention Transformer for Pedestrian Behavior Analysis](https://arxiv.org/abs/2601.01989)
  - Aly R. Elkammar, Karim M. Gamaleldin, Catherine M. Elias
  - Publish Date: 2026.01.05
  - Task: Prediction
  - Datasets: [JAAD](https://github.com/ykotseruba/JAAD)
  - SummaryÔºö
    - Introduces a transformer/video vision transformer based algorithm for pedestrian intention prediction, a key technology for autonomous driving.
    - The model uses different data modalities and achieves state-of-the-art performance on the JAAD dataset in metrics like Accuracy, AUC, and F1-score.
    - Investigates model design choices through extensive ablation studies.

---


**ÊÄªÁªì**:
- [Sparse Threats, Focused Defense: Criticality-Aware Robust Reinforcement Learning for Safe Autonomous Driving](https://arxiv.org/abs/2601.01800)
  - Qi Wei, Junchao Fan, Zhao Yang, Jianhua Wang, Jingkai Mao, Xiaolin Chang
  - Publish Date: 2026.01.05
  - Task: Planning
  - SummaryÔºö
    - Introduces Criticality-Aware Robust RL (CARRL), a novel adversarial training approach for handling sparse, safety-critical risks in autonomous driving, modeling the interaction as a general-sum game.
    - CARRL consists of a Risk Exposure Adversary (REA) that focuses on exposing safety-critical failures and a Risk-Targeted Robust Agent (RTRA) that learns to balance safety with driving efficiency.
    - Experimental results show the approach reduces collision rates by at least 22.66% compared to state-of-the-art baseline methods.

---


**ÊÄªÁªì**:
- [AlignDrive: Aligned Lateral-Longitudinal Planning for End-to-End Autonomous Driving](https://arxiv.org/abs/2601.01762)
  - Yanhao Wu, Haoyang Zhang, Fei He, Rui Wu, Congpei Qiu, Liang Gao, Wei Ke, Tong Zhang
  - Publish Date: 2026.01.05
  - Task: Planning
  - Datasets: [Bench2Drive](https://bench2drive.github.io/)
  - SummaryÔºö
    - A novel cascaded framework for end-to-end autonomous driving that explicitly conditions longitudinal planning on the drive path to enable coordinated lateral and longitudinal planning.
    - Introduces a path-conditioned formulation that simplifies longitudinal reasoning by predicting displacements along the drive path rather than full 2D waypoints.
    - Proposes a planning-oriented data augmentation strategy to simulate safety-critical events like vehicle cut-ins, improving collision avoidance and safety.

---


**ÊÄªÁªì**:
- [LabelAny3D: Label Any Object 3D in the Wild](https://arxiv.org/abs/2601.01676)
  - Jin Yao, Radowan Mahmud Redoy, Sebastian Elbaum, Matthew B. Dwyer, Zezhou Cheng
  - Publisher: University of Virginia
  - Publish Date: 2026.01.04
  - Task: Detection
  - Datasets: [COCO3D](https://cocodataset.org/)
  - SummaryÔºö
    - LabelAny3D, an analysis-by-synthesis framework that reconstructs holistic 3D scenes from 2D images to efficiently produce high-quality 3D bounding box annotations.
    - Introduces COCO3D, a new benchmark for open-vocabulary monocular 3D detection derived from MS-COCO, covering object categories absent from existing 3D datasets.
    - Annotations generated by LabelAny3D improve monocular 3D detection performance across benchmarks, outperforming prior auto-labeling approaches.

---


**ÊÄªÁªì**:
- [DrivingGen: A Comprehensive Benchmark for Generative Video World Models in Autonomous Driving](https://arxiv.org/abs/2601.01528)
  - Yang Zhou, Hao Shao, Letian Wang, Zhuofan Zong, Hongsheng Li, Steven L. Waslander
  - Publish Date: 2026.01.04
  - Task: Prediction
  - Datasets: [Waymo](https://waymo.com/open/), [nuScenes](https://www.nuscenes.org/), [KITTI](http://www.cvlibs.net/datasets/kitti/), [Argoverse](https://www.argoverse.org/), [BDD100K](https://bdd-data.berkeley.edu/), [CARLA](https://carla.org/)
  - SummaryÔºö
    - DrivingGen, the first comprehensive benchmark for generative driving world models, combining a diverse evaluation dataset with a suite of new metrics.
    - The benchmark assesses visual realism, trajectory plausibility, temporal coherence, and controllability to foster reliable and deployable driving world models.
    - Evaluation of 14 state-of-the-art models reveals trade-offs between general models and driving-specific ones, offering a unified framework for scalable simulation and planning.

---


**ÊÄªÁªì**:
- [ParkGaussian: Surround-view 3D Gaussian Splatting for Autonomous Parking](https://arxiv.org/abs/2601.01386)
  - Xiaobao Wei, Zhangjie Ye, Yuxiang Gu, Zunjie Zhu, Yunfei Guo, Yingying Shen, Shan Zhao, Ming Lu, Haiyang Sun, Bing Wang, Guang Chen, Rongfeng Lu, Hangjun Ye
  - Publisher: Xiaomi EV
  - Publish Date: 2026.01.04
  - Project Page: [ParkGaussian](https://github.com/wm-research/ParkGaussian)
  - Code: [ParkGaussian](https://github.com/wm-research/ParkGaussian)
  - Task: Perception
  - Datasets: [ParkRecon3D](https://github.com/wm-research/ParkGaussian)
  - SummaryÔºö
    - Proposes ParkGaussian, the first framework integrating 3D Gaussian Splatting (3DGS) for parking scene reconstruction.
    - Introduces a slot-aware reconstruction strategy that leverages parking perception methods to enhance synthesis quality in slot regions for better downstream task alignment.
    - Curates the first benchmark, ParkRecon3D, for parking scene reconstruction, featuring surround-view fisheye camera data and dense parking slot annotations.

---


**ÊÄªÁªì**:
- [PatchBlock: A Lightweight Defense Against Adversarial Patches for Embedded EdgeAI Devices](https://arxiv.org/abs/2601.00367)
  - Nandish Chattopadhyay, Abdul Basit, Amira Guesmi, Muhammad Abdullah Hanif, Bassem Ouni, Muhammad Shafique
  - Publisher: New York University Abu Dhabi, University of Sousse, Technische Universit√§t Wien
  - Publish Date: 2026.01.01
  - Task: Perception
  - SummaryÔºö
    - PatchBlock, a lightweight framework to detect and neutralize adversarial patches in images for EdgeAI applications, operating as a pre-processing module at the sensor level.
    - The framework uses a three-stage pipeline: Chunking, Separating via a redesigned isolation forest, and Mitigating via dimensionality reduction on identified outliers.
    - PatchBlock is model- and patch-agnostic, recovers up to 77% of model accuracy under strong patch attacks, and outperforms state-of-the-art defenses in efficiency for computation time and energy consumption.

---


**ÊÄªÁªì**:
- [Rectifying Adversarial Examples Using Their Vulnerabilities](https://arxiv.org/abs/2601.00270)
  - Fumiya Morimoto, Ryuto Morita, Satoshi Ono
  - Publisher: University of Miyazaki
  - Publish Date: 2026.01.01
  - Task: Perception
  - Datasets: [CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html), [ImageNet](https://www.image-net.org/)
  - SummaryÔºö
    - Proposes a method to rectify adversarial examples (AEs) by re-attacking them to move beyond decision boundaries, aiming to estimate the correct labels of their original inputs.
    - The method addresses AEs from white-box attacks and shows consistent performance against various attacks, including targeted and black-box attacks, without requiring parameter adjustments or preliminary training.

---


**ÊÄªÁªì**:
- [Dichotomous Diffusion Policy Optimization](https://arxiv.org/abs/2601.00898)
  - Ruiming Liang, Yinan Zheng, Kexin Zheng, Tianyi Tan, Jianxiong Li, Liyuan Mao, Zhihao Wang, Guang Chen, Hangjun Ye, Jingjing Liu, Jinqiao Wang, Xianyuan Zhan
  - Publisher: Huazhong University of Science and Technology, Xiaomi EV
  - Publish Date: 2025.12.31
  - Task: Planning, Control
  - Datasets: [ExORL](https://github.com/rail-berkeley/ExORL), [OGBench](https://github.com/OpenGVLab/ogbench), [NAVSIM](https://github.com/autonomousvision/navsim)
  - SummaryÔºö
    - Proposes DIPOLE, a novel RL algorithm for stable and controllable diffusion policy optimization, using a greedified policy regularization scheme.
    - Decomposes the optimal policy into a pair of dichotomous policies for reward maximization and minimization, enabling flexible control over greediness during inference.
    - Demonstrates effectiveness in offline and offline-to-online RL settings and trains a large VLA model for end-to-end autonomous driving on the NAVSIM benchmark.

---


**ÊÄªÁªì**:
- [Semi-Supervised Diversity-Aware Domain Adaptation for 3D Object detection](https://arxiv.org/abs/2512.24922)
  - Bart≈Çomiej Olber, Jakub Winter, Pawe≈Ç Wawrzy≈Ñski, Andrii Gamalii, Daniel G√≥rniak, Marcin ≈Åojek, Robert Nowak, Krystian Radlak
  - Publish Date: 2025.12.31
  - Task: Detection
  - SummaryÔºö
    - A novel lidar domain adaptation method for 3D object detection based on neuron activation patterns, requiring only a small, diverse, and representative annotated subset from the target domain.
    - The approach uses a minimal annotation budget and incorporates post-training techniques inspired by continual learning to prevent weight drift from the original model.
    - Empirical evaluation shows the method outperforms both linear probing and state-of-the-art domain adaptation techniques for cross-domain generalization in autonomous driving.

---


**ÊÄªÁªì**:
- [LSRE: Latent Semantic Rule Encoding for Real-Time Semantic Risk Detection in Autonomous Driving](https://arxiv.org/abs/2512.24712)
  - Qian Cheng, Weitao Zhou, Cheng Jing, Nanshan Deng, Junze Wen, Zhaoyang Liu, Kun Jiang, Diange Yang
  - Publish Date: 2025.12.31
  - Task: Perception
  - Datasets: [CARLA](https://carla.org/)
  - SummaryÔºö
    - LSRE, a Latent Semantic Rule Encoding framework that converts sparsely sampled VLM judgments into decision boundaries in a world model's latent space for real-time semantic risk assessment.
    - Enables real-time semantic risk detection at 10 Hz without per-frame VLM queries, achieving accuracy comparable to a large VLM baseline with earlier hazard anticipation and low latency.
    - Generalizes to rarely seen semantic-similar test cases, offering a deployable mechanism for language-guided semantic safety monitoring in autonomous driving.

---


**ÊÄªÁªì**:
- [Counterfactual VLA: Self-Reflective Vision-Language-Action Model with Adaptive Reasoning](https://arxiv.org/abs/2512.24426)
  - Zhenghao "Mark" Peng, Wenhao Ding, Yurong You, Yuxiao Chen, Wenjie Luo, Thomas Tian, Yulong Cao, Apoorva Sharma, Danfei Xu, Boris Ivanovic, Boyi Li, Bolei Zhou, Yan Wang, Marco Pavone
  - Publisher: Stanford University, NVIDIA, University of California, Los Angeles, University of California, Berkeley, University of Michigan, Tsinghua University
  - Publish Date: 2025.12.30
  - Task: Planning, Reasoning
  - SummaryÔºö
    - Introduces Counterfactual VLA (CF-VLA), a self-reflective VLA framework that enables reasoning about and revising planned actions before execution via counterfactual reasoning.
    - Proposes a rollout-filter-label pipeline to efficiently mine high-value scenes and label counterfactual reasoning traces for training.
    - Demonstrates improvements in trajectory accuracy (up to 17.6%) and safety metrics (20.5%), with adaptive reasoning enabled primarily in challenging scenarios.

---


**ÊÄªÁªì**:
- [Spatial-aware Vision Language Model for Autonomous Driving](https://arxiv.org/abs/2512.24331)
  - Weijie Wei, Zhipeng Luo, Ling Feng, Venice Erin Liong
  - Publish Date: 2025.12.30
  - Task: End-to-End
  - SummaryÔºö
    - LVLDrive (LiDAR-Vision-Language), a novel framework designed to upgrade existing Vision-Language Models (VLMs) with robust 3D metric spatial understanding for autonomous driving by incorporating LiDAR point cloud as an extra input modality.
    - Introduces a Gradual Fusion Q-Former to incrementally inject LiDAR features, ensuring stability and preservation of the pre-trained VLM's knowledge base.
    - Develops a spatial-aware question-answering (SA-QA) dataset to explicitly teach the model advanced 3D perception and reasoning capabilities, achieving superior performance on driving benchmarks.

---


**ÊÄªÁªì**:
- [MambaSeg: Harnessing Mamba for Accurate and Efficient Image-Event Semantic Segmentation](https://arxiv.org/abs/2512.24243)
  - Fuqiang Gu, Yuanke Li, Xianlei Long, Kangping Ji, Chao Chen, Qingyi Gu, Zhenliang Ni
  - Publish Date: 2025.12.30
  - Task: Perception
  - Datasets: [DDD17](https://github.com/SensorsINI/DDD17), [DSEC](https://dsec.ifi.uzh.ch/)
  - SummaryÔºö
    - MambaSeg, a novel dual-branch semantic segmentation framework using parallel Mamba encoders to efficiently model RGB images and event streams.
    - Introduces a Dual-Dimensional Interaction Module (DDIM) with Cross-Spatial and Cross-Temporal Interaction Modules for fine-grained fusion along spatial and temporal dimensions to reduce cross-modal ambiguity.
    - Achieves state-of-the-art performance on DDD17 and DSEC datasets with significantly reduced computational cost for efficient, scalable multimodal perception.

---


**ÊÄªÁªì**:
- [Mirage: One-Step Video Diffusion for Photorealistic and Coherent Asset Editing in Driving Scenes](https://arxiv.org/abs/2512.24227)
  - Shuyun Wang, Haiyang Sun, Bing Wang, Hangjun Ye, Xin Yu
  - Publisher: wm-research
  - Publish Date: 2025.12.30
  - Project Page: [Mirage](https://github.com/wm-research/mirage)
  - Code: [Mirage](https://github.com/wm-research/mirage)
  - Task: Perception
  - Datasets: None
  - SummaryÔºö
    - Mirage, a one-step video diffusion model for photorealistic and coherent asset editing in driving scenes, building on a text-to-video diffusion prior for temporal consistency.
    - Introduces injection of temporally agnostic latents from a pretrained 2D encoder into a 3D decoder to restore detail while preserving causal structures.
    - Proposes a two-stage data alignment strategy combining coarse 3D alignment and fine 2D refinement to mitigate distribution mismatch and improve pose alignment for inserted assets.

---


**ÊÄªÁªì**:
- [Guided Diffusion-based Generation of Adversarial Objects for Real-World Monocular Depth Estimation Attacks](https://arxiv.org/abs/2512.24111)
  - Yongtao Chen, Yanbo Wang, Wentao Zhao, Guole Shen, Tianchen Deng, Jingchuan Wang
  - Publish Date: 2025.12.30
  - Task: Perception
  - SummaryÔºö
    - Introduces a training-free generative adversarial attack framework for Monocular Depth Estimation (MDE) that generates naturalistic, scene-consistent adversarial objects via a diffusion-based conditional generation process.
    - The framework includes a Salient Region Selection module and a Jacobian Vector Product Guidance mechanism to steer adversarial gradients, enabling the generation of physically plausible objects that induce substantial adversarial depth shifts.
    - Demonstrates through extensive digital and physical experiments that the method outperforms existing attacks in effectiveness, stealthiness, and physical deployability, highlighting its implications for autonomous driving safety assessment.

---


**ÊÄªÁªì**:
- [Multi-Scenario Highway Lane-Change Intention Prediction: A Temporal Physics-Informed Multi-Modal Framework](https://arxiv.org/abs/2512.24075)
  - Jiazhao Shi, Ziyu Wang, Yichen Lin, Shoufeng Lu
  - Publish Date: 2025.12.30
  - Task: Prediction
  - Datasets: [highD](https://www.highd-dataset.com/), [exiD](https://exid-dataset.github.io/)
  - SummaryÔºö
    - Proposes Temporal Physics-Informed AI (TPI-AI), a hybrid framework for lane-change intention prediction that fuses deep temporal representations from a Bi-LSTM encoder with physics-inspired interaction features.
    - Employs imbalance-aware optimization and a LightGBM classifier, achieving robust performance across heterogeneous highway scenarios (straight and ramp-rich) on the highD and exiD datasets.

---


**ÊÄªÁªì**:
- [DriveExplorer: Images-Only Decoupled 4D Reconstruction with Progressive Restoration for Driving View Extrapolation](https://arxiv.org/abs/2512.23983)
  - Yuang Jia, Jinlong Wang, Jiayi Zhao, Chunlam Li, Shunzhou Wang, Wei Gao
  - Publish Date: 2025.12.30
  - Task: Perception
  - SummaryÔºö
    - Presents a method for view extrapolation in autonomous driving using only images and optional camera poses, eliminating the need for expensive sensors or labels.
    - Introduces a deformable 4D Gaussian framework for scene reconstruction and a progressive restoration process using a video diffusion model to refine novel viewpoint renderings.
    - Generates higher-quality extrapolated images compared to baselines by iteratively enhancing 4D Gaussian Splatting renders with a diffusion model.

---


**ÊÄªÁªì**:
- [Rethinking the Spatio-Temporal Alignment of End-to-End 3D Perception](https://arxiv.org/abs/2512.23635)
  - Xiaoyu Li, Peidong Li, Xian Wu, Long Shi, Dedong Liu, Yitao Wu, Jiajia Fu, Dixiao Cui, Lijun Zhao, Lining Sun
  - Publish Date: 2025.12.29
  - Task: Perception
  - Datasets: [nuScenes](https://www.nuscenes.org/)
  - SummaryÔºö
    - Proposes HAT, a spatio-temporal alignment module that adaptively decodes the optimal alignment proposal from multiple hypotheses without direct supervision for temporal modeling in end-to-end autonomous driving perception.
    - HAT utilizes multiple explicit motion models to generate spatial anchors and motion-aware feature proposals, performing multi-hypothesis decoding by incorporating semantic and motion cues.
    - Achieves state-of-the-art tracking results (46.0% AMOTA on nuScenes test set) and enhances perception accuracy and planning robustness in end-to-end autonomous driving, especially when semantics are corrupted.

---


**ÊÄªÁªì**:
- [A Kalman Filter-Based Disturbance Observer for Steer-by-Wire Systems](https://arxiv.org/abs/2512.23593)
  - Nikolai Beving, Jonas Marxen, Steffen Mueller, Johannes Betz
  - Publisher: Technical University of Munich
  - Publish Date: 2025.12.29
  - Task: Control
  - SummaryÔºö
    - A Kalman filter-based disturbance observer for Steer-by-Wire systems that estimates high-frequency driver torque using only motor state measurements, without needing costly direct torque sensors.
    - The observer models driver passive torque as an extended state with a PT1-lag approximation and integrates it into both linear and nonlinear system models, with a nonlinear extended Kalman Filter showing improved performance in handling frictional nonlinearities.
    - The proposed method accurately reconstructs driver-induced disturbances with minimal delay (14ms), addressing a key limitation in existing approaches for autonomous driving-compatible steering systems.

---


**ÊÄªÁªì**:
- [Unsupervised Learning for Detection of Rare Driving Scenarios](https://arxiv.org/abs/2512.23585)
  - Dat Le, Thomas Manhardt, Moritz Venator, Johannes Betz
  - Publish Date: 2025.12.29
  - Task: Detection
  - SummaryÔºö
    - Proposes an unsupervised learning framework using Deep Isolation Forest (DIF) to detect rare and hazardous driving scenarios from naturalistic driving data.
    - Leverages t-SNE for dimensionality reduction and visualization to improve the interpretability of detected anomalies.
    - Evaluates the approach using a proxy ground truth, demonstrating its effectiveness for scalable anomaly detection in autonomous driving systems.

---


**ÊÄªÁªì**:
- [Assessing behaviour coverage in a multi-agent system simulation for autonomous vehicle testing](https://arxiv.org/abs/2512.23445)
  - Manuel Franco-Vivo
  - Publish Date: 2025.12.29
  - Task: Planning
  - SummaryÔºö
    - Proposes a systematic approach to measure and assess behaviour coverage within a multi-agent simulation environment for autonomous vehicle testing.
    - Introduces a Model Predictive Control (MPC) pedestrian agent designed to encourage interesting tests and promote realistic behaviour.

---


**ÊÄªÁªì**:
- [DriveLaW:Unifying Planning and Video Generation in a Latent Driving World](https://arxiv.org/abs/2512.23421)
  - Tianze Xia, Yongkang Li, Lijun Zhou, Jingfeng Yao, Kaixin Xiong, Haiyang Sun, Bing Wang, Kun Ma, Guang Chen, Hangjun Ye, Wenyu Liu, Xinggang Wang
  - Publisher: Huazhong University of Science and Technology, Xiaomi EV
  - Publish Date: 2025.12.29
  - Task: Planning
  - Datasets: [NAVSIM](https://github.com/autonomousvision/navsim)
  - SummaryÔºö
    - DriveLaW, a novel paradigm that unifies video generation and motion planning for autonomous driving by injecting latent representations from a video generator directly into the planner.
    - The framework consists of DriveLaW-Video, a world model for high-fidelity forecasting, and DriveLaW-Act, a diffusion planner that generates consistent trajectories from the latent representations.
    - Achieves state-of-the-art results, surpassing prior work by 33.3% in FID and 1.8% in FVD for video prediction and setting a new record on the NAVSIM planning benchmark.

---


**ÊÄªÁªì**:
- [A Human-Oriented Cooperative Driving Approach: Integrating Driving Intention, State, and Conflict](https://arxiv.org/abs/2512.23220)
  - Qin Wang, Shanmin Pang, Jianwu Fang, Shengye Dong, Fuhao Liu, Jianru Xue, Chen Lv
  - Publish Date: 2025.12.29
  - Code: [HOCD](https://github.com/i-Qin/HOCD)
  - Task: Planning
  - SummaryÔºö
    - A Human-Oriented Cooperative Driving (HOCD) approach that minimizes human-machine conflict by prioritizing driver intention and state at both tactical and operational levels.
    - At the tactical level, an intention-aware trajectory planning method uses intention consistency cost to align trajectories with driver intention.
    - At the operational level, a reinforcement learning-based control authority allocation strategy optimizes policy to match driver state with authority allocation, enhancing performance and reducing conflict.

---


**ÊÄªÁªì**:
- [Exploring Syn-to-Real Domain Adaptation for Military Target Detection](https://arxiv.org/abs/2512.23208)
  - Jongoh Jeong, Youngjin Oh, Gyeongrae Nam, Jeongeun Lee, Kuk-Jin Yoon
  - Publisher: KAIST
  - Publish Date: 2025.12.29
  - Task: Detection
  - Datasets: [Web-Collected Military Target Dataset](https://arxiv.org/abs/2512.23208)
  - SummaryÔºö
    - Proposes generating RGB-based synthetic data using Unreal Engine for military target detection to address the lack of real datasets and high costs of SAR data.
    - Benchmarks state-of-the-art domain adaptation methods on a synthetic-to-real train-val dataset pair, finding methods using minimal image hints outperform unsupervised/semi-supervised approaches.
    - Highlights the challenges of domain adaptation for military target detection across varying environments and the limitations of current methods.

---
