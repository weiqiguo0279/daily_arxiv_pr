# ğŸ“š æ¯æ—¥ arXiv è®ºæ–‡æ€»ç»“(LLM4AD/VLM4AD/VLA4AD)

**æ—¥æœŸ**: 2026-01-09
**è®ºæ–‡æ•°é‡**: 2 ç¯‡
**LLM**: DeepSeek (deepseek-chat)

---


- [ThinkDrive: Chain-of-Thought Guided Progressive Reinforcement Learning Fine-Tuning for Autonomous Driving](https://arxiv.org/abs/2601.04714)
  - Chang Zhao, Zheming Yang, Yunqing Hu, Qi Guo, Zijian Wang, Pengcheng Li, Wen Ji
  - Publish Date: 2026.01.08
  - Task: Planning
  - Summaryï¼š
    - ThinkDrive, a Chain-of-Thought (CoT) guided progressive reinforcement learning fine-tuning framework for autonomous driving that synergizes explicit reasoning with difficulty-aware adaptive policy optimization.
    - The method employs a two-stage training strategy: first performing supervised fine-tuning (SFT) using CoT explanations, then applying progressive RL with a difficulty-aware adaptive policy optimizer.

---


- [UniDrive-WM: Unified Understanding, Planning and Generation World Model For Autonomous Driving](https://arxiv.org/abs/2601.04453)
  - Zhexiao Xiong, Xin Ye, Burhan Yaman, Sheng Cheng, Yiren Lu, Jingru Luo, Nathan Jacobs, Liu Ren
  - Publish Date: 2026.01.07
  - Project Page: [UniDrive-WM](https://unidrive-wm.github.io/UniDrive-WM)
  - Task: Planning
  - Datasets: [Bench2Drive](https://bench2drive.github.io/)
  - Summaryï¼š
    - UniDrive-WM, a unified VLM-based world model that jointly performs driving-scene understanding, trajectory planning, and trajectory-conditioned future image generation within a single architecture.
    - The model uses predicted trajectories to condition a VLM-based image generator, producing future frames that provide supervisory signals to iteratively refine understanding and planning.
    - Experiments on Bench2Drive show improvements of 5.9% in L2 trajectory error and 9.2% in collision rate over previous methods, demonstrating the advantage of tightly integrated reasoning, planning, and generation.

---
