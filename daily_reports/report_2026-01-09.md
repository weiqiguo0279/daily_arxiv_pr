# üìö ÊØèÊó• arXiv ËÆ∫ÊñáÊÄªÁªì

**Êó•Êúü**: 2026-01-09
**ËÆ∫ÊñáÊï∞Èáè**: 2 ÁØá
**LLM**: DeepSeek (deepseek-chat)

---


- [ThinkDrive: Chain-of-Thought Guided Progressive Reinforcement Learning Fine-Tuning for Autonomous Driving](https://arxiv.org/abs/2601.04714)
  - Chang Zhao, Zheming Yang, Yunqing Hu, Qi Guo, Zijian Wang, Pengcheng Li, Wen Ji
  - Publish Date: 2026.01.08
  - Task: Planning
  - SummaryÔºö
    - ThinkDrive, a Chain-of-Thought (CoT) guided progressive reinforcement learning fine-tuning framework for autonomous driving that synergizes explicit reasoning with difficulty-aware adaptive policy optimization.
    - Employs a two-stage training strategy: first supervised fine-tuning with CoT explanations, then progressive RL with a difficulty-aware adaptive policy optimizer that adjusts learning intensity based on sample complexity.
    - Outperforms strong RL baselines on evaluation metrics and shows a 2B-parameter model trained with this method surpasses GPT-4o on the exam metric.

---


- [UniDrive-WM: Unified Understanding, Planning and Generation World Model For Autonomous Driving](https://arxiv.org/abs/2601.04453)
  - Zhexiao Xiong, Xin Ye, Burhan Yaman, Sheng Cheng, Yiren Lu, Jingru Luo, Nathan Jacobs, Liu Ren
  - Publisher: Washington University in St. Louis, Bosch Research
  - Publish Date: 2026.01.07
  - Project Page: [UniDrive-WM](https://unidrive-wm.github.io/UniDrive-WM)
  - Task: Planning
  - Datasets: [Bench2Drive](https://bench2drive.github.io/)
  - SummaryÔºö
    - UniDrive-WM, a unified VLM-based world model that jointly performs driving-scene understanding, trajectory planning, and trajectory-conditioned future image generation within a single architecture.
    - The model's trajectory planner predicts a future trajectory, which conditions a VLM-based image generator to produce plausible future frames, providing supervisory signals that enhance understanding and iteratively refine trajectory generation.
    - Experiments on Bench2Drive show UniDrive-WM improves planning performance by 5.9% in L2 error and 9.2% in collision rate over the previous best method, demonstrating advantages of tightly integrating VLM-driven reasoning, planning, and generative world modeling.

---
