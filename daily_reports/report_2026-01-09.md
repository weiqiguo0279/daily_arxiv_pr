# üìö ÊØèÊó• arXiv ËÆ∫ÊñáÊÄªÁªì

**Êó•Êúü**: 2026-01-09
**ËÆ∫ÊñáÊï∞Èáè**: 10 ÁØá
**LLM**: DeepSeek (deepseek-chat)

---


- [Mesh4D: 4D Mesh Reconstruction and Tracking from Monocular Video](https://arxiv.org/abs/2601.05251)
  - Zeren Jiang, Chuanxia Zheng, Iro Laina, Diane Larlus, Andrea Vedaldi
  - Publisher: University of Oxford, NAVER LABS Europe
  - Publish Date: 2026.01.08
  - Task: Perception
  - SummaryÔºö
    - Mesh4D, a feed-forward model for monocular 4D mesh reconstruction, reconstructs a dynamic object's complete 3D shape and motion as a deformation field from a video.
    - Introduces a compact latent space learned via an autoencoder guided by skeletal priors during training, enabling single-pass encoding of entire animation sequences without skeletal input at inference.
    - Employs a latent diffusion model conditioned on the input video and first-frame mesh to predict the full animation, outperforming prior methods in 3D shape and deformation recovery.

---


- [RL-AWB: Deep Reinforcement Learning for Auto White Balance Correction in Low-Light Night-time Scenes](https://arxiv.org/abs/2601.05249)
  - Yuan-Kang Lee, Kuan-Lin Chen, Chia-Che Chang, Yu-Lun Liu
  - Publish Date: 2026.01.08
  - Project Page: [RL-AWB](https://ntuneillee.github.io/research/rl-awb/)
  - Task: Perception
  - Datasets: [Multi-sensor Nighttime Dataset](https://ntuneillee.github.io/research/rl-awb/)
  - SummaryÔºö
    - RL-AWB, a novel framework combining statistical methods with deep reinforcement learning for nighttime white balance, featuring a statistical algorithm for salient gray pixel detection and illumination estimation.
    - The first deep reinforcement learning approach for color constancy, dynamically optimizing parameters per image by mimicking professional AWB tuning experts.
    - Introduces the first multi-sensor nighttime dataset to facilitate cross-sensor evaluation, demonstrating superior generalization across low-light and well-illuminated images.

---


- [QNeRF: Neural Radiance Fields on a Simulated Gate-Based Quantum Computer](https://arxiv.org/abs/2601.05250)
  - Daniele Lizzio Bosco, Shuteng Wang, Giuseppe Serra, Vladislav Golyanik
  - Publisher: University of Udine, University of Siegen
  - Publish Date: 2026.01.08
  - Task: 3D Representation Learning
  - Datasets: [Blender](https://www.blender.org/), [LLFF](https://github.com/Fyusion/LLFF)
  - SummaryÔºö
    - QNeRF, the first hybrid quantum-classical model for novel-view synthesis from 2D images, leveraging parameterised quantum circuits for compact 3D scene representation.
    - Introduces two variants: Full QNeRF for enhanced representational capabilities and Dual-Branch QNeRF for reduced complexity and hardware compatibility.
    - Experiments show QNeRF matches or outperforms classical NeRF baselines in quality while using less than half the number of parameters, suggesting quantum ML as a competitive alternative for 3D representation learning.

---


- [LaST$_{0}$: Latent Spatio-Temporal Chain-of-Thought for Robotic Vision-Language-Action Model](https://arxiv.org/abs/2601.05248)
  - Zhuoyang Liu, Jiaming Liu, Hao Chen, Ziyu Guo, Chengkai Hou, Chenyang Gu, Jiale Yu, Xiangju Mi, Renrui Zhang, Zhengping Che, Jian Tang, Pheng-Ann Heng, Shanghang Zhang
  - Publisher: The Chinese University of Hong Kong, Mila - Quebec AI Institute
  - Publish Date: 2026.01.08
  - Project Page: [LaST$_{0}$](https://sites.google.com/view/last0)
  - Task: Reasoning
  - SummaryÔºö
    - LaST$_{0}$, a framework enabling efficient reasoning before acting through a Latent Spatio-Temporal Chain-of-Thought (CoT) to capture fine-grained physical and robotic dynamics that are difficult to verbalize.
    - Introduces a token-efficient latent CoT space modeling future visual dynamics, 3D structure, and robot proprioceptive states, extended across time for temporally consistent implicit reasoning.
    - Employs a dual-system Mixture-of-Transformers architecture with heterogeneous training frequencies, allowing adaptive switching between low-frequency reasoning and high-frequency action inference.

---


- [Pixel-Perfect Visual Geometry Estimation](https://arxiv.org/abs/2601.05246)
  - Gangwei Xu, Haotong Lin, Hongcheng Luo, Haiyang Sun, Bing Wang, Guang Chen, Sida Peng, Hangjun Ye, Xin Yang
  - Publisher: Huazhong University of Science and Technology, Xiaomi EV
  - Publish Date: 2026.01.08
  - Task: Perception
  - SummaryÔºö
    - Presents pixel-perfect visual geometry models, Pixel-Perfect Depth (PPD) and its video extension (PPVD), that predict high-quality, flying-pixel-free point clouds using generative modeling in pixel space.
    - Introduces key designs for efficiency: Semantics-Prompted DiT to incorporate semantic representations, and a Cascade DiT architecture that progressively increases image tokens.
    - Extends to video with a Semantics-Consistent DiT and reference-guided token propagation to maintain temporal coherence, achieving state-of-the-art performance in generative monocular and video depth estimation.

---


- [Optimal Lower Bounds for Online Multicalibration](https://arxiv.org/abs/2601.05245)
  - Natalie Collina, Jiuyao Lu, Georgy Noarov, Aaron Roth
  - Publish Date: 2026.01.08
  - SummaryÔºö
    - Proves tight lower bounds for online multicalibration, establishing an information-theoretic separation from marginal calibration.
    - In the general setting, proves an $Œ©(T^{2/3})$ lower bound on expected multicalibration error using three disjoint binary groups, matching known upper bounds and exceeding the upper bound for marginal calibration.
    - For group functions dependent only on context, establishes an $\widetildeŒ©(T^{2/3})$ lower bound via a $Œò(T)$-sized group family, again matching upper bounds up to logarithmic factors.

---


- [GREx: Generalized Referring Expression Segmentation, Comprehension, and Generation](https://arxiv.org/abs/2601.05244)
  - Henghui Ding, Chang Liu, Shuting He, Xudong Jiang, Yu-Gang Jiang
  - Publish Date: 2026.01.08
  - Project Page: [GREx](https://henghuiding.github.io/GREx)
  - Code: [GREx](https://henghuiding.github.io/GREx)
  - Task: Perception
  - Datasets: [gRefCOCO](https://henghuiding.github.io/GREx)
  - SummaryÔºö
    - Introduces GREx, a set of three new benchmarks (GRES, GREC, GREG) that generalize classic Referring Expression tasks to allow expressions identifying an arbitrary number of objects, including multi-target and no-target cases.
    - Constructs the first large-scale GREx dataset gRefCOCO, which is backward-compatible with existing REx datasets, to study the performance gap of existing methods on these generalized tasks.
    - Proposes a baseline method ReLA that adaptively divides images into regions and models region-region and region-language dependencies, achieving state-of-the-art results on GRES and GREC.

---


- [Generate, Transfer, Adapt: Learning Functional Dexterous Grasping from a Single Human Demonstration](https://arxiv.org/abs/2601.05243)
  - Xingyi He, Adhitya Polavaram, Yunhao Cao, Om Deshmukh, Tianrui Wang, Xiaowei Zhou, Kuan Fang
  - Publish Date: 2026.01.08
  - Task: End-to-End
  - SummaryÔºö
    - CorDex, a framework that robustly learns dexterous functional grasps of novel objects from synthetic data generated from just a single human demonstration.
    - Introduces a correspondence-based data engine that generates diverse, high-quality training data in simulation by transferring and adapting the expert grasp to generated object instances.
    - Presents a multimodal prediction network with a local-global fusion module and importance-aware sampling for robust and efficient prediction of functional dexterous grasps.

---


- [GDPO: Group reward-Decoupled Normalization Policy Optimization for Multi-reward RL Optimization](https://arxiv.org/abs/2601.05242)
  - Shih-Yang Liu, Xin Dong, Ximing Lu, Shizhe Diao, Peter Belcak, Mingjie Liu, Min-Hung Chen, Hongxu Yin, Yu-Chiang Frank Wang, Kwang-Ting Cheng, Yejin Choi, Jan Kautz, Pavlo Molchanov
  - Publisher: NVIDIA, University of Washington, University of California San Diego, KAIST
  - Publish Date: 2026.01.08
  - Task: Reasoning
  - SummaryÔºö
    - Introduces GDPO, a new policy optimization method for multi-reward RL that decouples the normalization of individual rewards to preserve their relative differences, addressing issues in GRPO.
    - Demonstrates that directly applying GRPO to normalize distinct rollout reward combinations causes them to collapse into identical advantage values, leading to suboptimal convergence.
    - Shows GDPO outperforms GRPO across tasks like tool calling, math reasoning, and coding reasoning, improving both correctness and constraint adherence metrics with better training stability.

---


- [RoboVIP: Multi-View Video Generation with Visual Identity Prompting Augments Robot Manipulation](https://arxiv.org/abs/2601.05241)
  - Boyang Wang, Haoran Zhang, Shujie Zhang, Jinkun Hao, Mingda Jia, Qi Lv, Yucheng Mao, Zhaoyang Lyu, Jia Zeng, Xudong Xu, Jiangmiao Pang
  - Publish Date: 2026.01.08
  - Task: Control
  - SummaryÔºö
    - Introduces RoboVIP, a method for multi-view video generation using visual identity prompting to augment robot manipulation data, addressing the scarcity of large-scale, diverse real-world data.
    - Proposes a scalable pipeline to curate a visual identity pool from large robotics datasets, using exemplar images to guide diffusion models for generating temporally coherent, multi-view observations.
    - Demonstrates that training downstream vision-language-action and visuomotor policies with this augmented data yields consistent performance gains in both simulation and real-robot settings.

---
