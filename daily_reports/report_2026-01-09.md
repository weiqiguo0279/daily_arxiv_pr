# üìö ÊØèÊó• arXiv ËÆ∫ÊñáÊÄªÁªì

**Êó•Êúü**: 2026-01-09
**ËÆ∫ÊñáÊï∞Èáè**: 10 ÁØá
**LLM**: DeepSeek (deepseek-chat)

---


**ÊÄªÁªì**:
- [LaST$_{0}$: Latent Spatio-Temporal Chain-of-Thought for Robotic Vision-Language-Action Model](https://arxiv.org/abs/2601.05248)
  - Zhuoyang Liu, Jiaming Liu, Hao Chen, Ziyu Guo, Chengkai Hou, Chenyang Gu, Jiale Yu, Xiangju Mi, Renrui Zhang, Zhengping Che, Jian Tang, Pheng-Ann Heng, Shanghang Zhang
  - Publish Date: 2026.01.08
  - Project Page: [LaST$_{0}$](https://sites.google.com/view/last0)
  - Task: Reasoning
  - SummaryÔºö
    - LaST$_{0}$, a framework enabling efficient reasoning before acting through a Latent Spatio-Temporal Chain-of-Thought (CoT) that captures fine-grained physical and robotic dynamics difficult to verbalize.
    - It introduces a token-efficient latent CoT space modeling future visual dynamics, 3D structure, and robot proprioceptive states, extended across time for temporally consistent implicit reasoning.
    - LaST$_{0}$ uses a dual-system Mixture-of-Transformers architecture with heterogeneous training frequencies, improving success rates over prior VLA methods in simulated and real-world manipulation tasks while achieving faster inference.

---


**ÊÄªÁªì**:
- [CLAP: Contrastive Latent Action Pretraining for Learning Vision-Language-Action Models from Human Videos](https://arxiv.org/abs/2601.04061)
  - Chubin Zhang, Jianan Wang, Zifeng Gao, Yue Su, Tianru Dai, Cai Zhou, Jiwen Lu, Yansong Tang
  - Publish Date: 2026.01.07
  - Project Page: [CLAP](https://lin-shan.com/CLAP/)
  - Task: Control
  - SummaryÔºö
    - CLAP, a framework for pretraining Vision-Language-Action models from human videos by aligning visual latents with a proprioceptive latent space from robot trajectories via contrastive learning.
    - Introduces a dual-formulation VLA framework with CLAP-NTP for instruction following and CLAP-RF, a Rectified Flow-based policy for precise manipulation.
    - Proposes a Knowledge Matching regularization to mitigate catastrophic forgetting during fine-tuning, enabling effective skill transfer from human videos to robots.

---


**ÊÄªÁªì**:
- [Stable Language Guidance for Vision-Language-Action Models](https://arxiv.org/abs/2601.04052)
  - Zhihao Zhan, Yuhao Chen, Jiaying Zhou, Qinhan Lv, Hao Liu, Keze Wang, Liang Lin, Guangrun Wang
  - Publish Date: 2026.01.07
  - Task: Control
  - SummaryÔºö
    - Proposes Residual Semantic Steering (RSS), a probabilistic framework to address linguistic brittleness in Vision-Language-Action (VLA) models by disentangling physical affordance from semantic execution.
    - Introduces Monte Carlo Syntactic Integration to approximate the semantic posterior and Residual Affordance Steering, a dual-stream decoder to isolate language's causal influence.
    - Demonstrates state-of-the-art robustness against adversarial linguistic perturbations across diverse manipulation benchmarks.

---


**ÊÄªÁªì**:
- [State Backdoor: Towards Stealthy Real-world Poisoning Attack on Vision-Language-Action Model in State Space](https://arxiv.org/abs/2601.04266)
  - Ji Guo, Wenbo Jiang, Yansong Lin, Yijing Liu, Ruichen Zhang, Guomin Lu, Aiguo Chen, Xinshuo Han, Hongwei Li, Dusit Niyato
  - Publish Date: 2026.01.07
  - Task: Control
  - SummaryÔºö
    - Introduces State Backdoor, a novel backdoor attack on Vision-Language-Action (VLA) models that uses the robot arm's initial state as a stealthy trigger, overcoming limitations of visible visual triggers.
    - Proposes a Preference-guided Genetic Algorithm (PGA) to efficiently search the state space for optimal triggers that are both insusceptible and effective.
    - Demonstrates over 90% attack success rate on five VLA models across five real-world tasks without degrading performance on clean data, revealing a critical vulnerability in embodied AI systems.

---


**ÊÄªÁªì**:
- [A Vision-Language-Action Model with Visual Prompt for OFF-Road Autonomous Driving](https://arxiv.org/abs/2601.03519)
  - Liangdong Zhang, Yiming Nie, Haoyang Li, Fanjie Kong, Baobao Zhang, Shunxin Huang, Kai Fu, Chen Min, Liang Xiao
  - Publish Date: 2026.01.07
  - Task: Planning
  - Datasets: [RELLIS-3D](https://github.com/unmannedlab/RELLIS-3D)
  - SummaryÔºö
    - Proposes OFF-EMMA, an end-to-end multimodal framework for off-road autonomous driving, designed to overcome insufficient spatial perception and unstable reasoning in VLA models.
    - Introduces a visual prompt block using semantic segmentation masks to enhance spatial understanding and a chain-of-thought with self-consistency (COT-SC) reasoning strategy to improve planning robustness.

---


**ÊÄªÁªì**:
- [Limited Linguistic Diversity in Embodied AI Datasets](https://arxiv.org/abs/2601.03136)
  - Selma Wanna, Agnes Luhtaru, Jonathan Salfity, Ryan Barron, Juston Moore, Cynthia Matuszek, Mitch Pryor
  - Publish Date: 2026.01.06
  - Task: Reasoning
  - SummaryÔºö
    - Presents a systematic dataset audit of widely used Vision-Language-Action (VLA) corpora to characterize the linguistic variety of their instructions.
    - Quantifies instruction language along dimensions like lexical variety, duplication, semantic similarity, and syntactic complexity, finding many datasets rely on repetitive, template-like commands.
    - Aims to support more detailed dataset reporting, principled dataset selection, and curation strategies to broaden language coverage in embodied AI.

---


**ÊÄªÁªì**:
- [SOP: A Scalable Online Post-Training System for Vision-Language-Action Models](https://arxiv.org/abs/2601.03044)
  - Mingjie Pan, Siyuan Feng, Qinglin Zhang, Xinchen Li, Jianheng Song, Chendi Qu, Yi Wang, Chuankang Li, Ziyu Xiong, Zhi Chen, Yi Liu, Jianlan Luo
  - Publish Date: 2026.01.06
  - Task: Control
  - SummaryÔºö
    - SOP, a Scalable Online Post-training system enabling online, distributed, multi-task post-training of generalist VLA models directly in the physical world.
    - SOP uses a closed-loop fleet architecture for continuous on-policy experience streaming and asynchronous policy updates, supporting algorithms like HG-DAgger and RECAP.
    - The system improves large pretrained VLA models across real-world manipulation tasks (e.g., cloth folding, box assembly) while maintaining a single shared policy, with performance scaling near-linearly with fleet size.

---


**ÊÄªÁªì**:
- [VLM4VLA: Revisiting Vision-Language-Models in Vision-Language-Action Models](https://arxiv.org/abs/2601.03309)
  - Jianke Zhang, Xiaoyu Chen, Qiuyue Wang, Mingsheng Li, Yanjiang Guo, Yucheng Hu, Jiajun Zhang, Shuai Bai, Junyang Lin, Jianyu Chen
  - Publish Date: 2026.01.06
  - Task: Planning
  - SummaryÔºö
    - Introduces VLM4VLA, a minimal adaptation pipeline to convert general-purpose VLMs into VLA policies, finding it surprisingly competitive with more complex designs.
    - Through extensive studies, finds that a VLM's general capabilities are poor predictors of its downstream embodied task performance, challenging common assumptions.
    - Identifies the visual module in VLMs as the primary performance bottleneck and shows that injecting control-relevant supervision into the vision encoder yields consistent gains.

---


**ÊÄªÁªì**:
- [InternVLA-A1: Unifying Understanding, Generation and Action for Robotic Manipulation](https://arxiv.org/abs/2601.02456)
  - Junhao Cai, Zetao Cai, Jiafei Cao, Yilun Chen, Zeyu He, Lei Jiang, Hang Li, Hengjie Li, Yang Li, Yufei Liu, Yanan Lu, Qi Lv, Haoxiang Ma, Jiangmiao Pang, Yu Qiao, Zherui Qiu, Yanqing Shen, Xu Shi, Yang Tian, Bolun Wang, Hanqing Wang, Jiaheng Wang, Tai Wang, Xueyuan Wei, Chao Wu, Yiman Xie, Boyang Xing, Yuqiang Yang, Yuyin Yang, Qiaojun Yu, Feng Yuan, Jia Zeng, Jingjing Zhang, Shenghan Zhang, Shi Zhang, Zhuoma Zhaxi, Bowen Zhou, Yuanzhen Zhou, Yunsong Zhou, Hongrui Zhu, Yangkun Zhu, Yuchen Zhu
  - Publisher: Shanghai AI Laboratory, The Chinese University of Hong Kong, Shanghai Jiao Tong University, Tsinghua University, Zhejiang University, Sun Yat-sen University, The University of Hong Kong, Peking University, University of Science and Technology of China, Beihang University, Xiamen University, Wuhan University, Nankai University, Fudan University, Harbin Institute of Technology, Huazhong University of Science and Technology, Tongji University, East China Normal University, Central South University, Northwestern Polytechnical University, University of Electronic Science and Technology of China, South China University of Technology, Shenzhen University, University of Macau, City University of Hong Kong, Hong Kong Polytechnic University, Hong Kong University of Science and Technology, The University of Tokyo, Kyoto University, Osaka University, Tohoku University, Nagoya University, Kyushu University, Hokkaido University, Tokyo Institute of Technology, Keio University, Waseda University, University of Tsukuba, University of Electro-Communications, Chiba University, Yokohama National University, Kanazawa University, Okayama University, Hiroshima University, Kumamoto University, Kagoshima University, University of the Ryukyus, University of Aizu, Japan Advanced Institute of Science and Technology, Nara Institute of Science and Technology, Tokyo University of Agriculture and Technology, Tokyo Metropolitan University, Tokyo University of Science, Sophia University, Meiji University, Aoyama Gakuin University, Rikkyo University, Chuo University, Hosei University, Kwansei Gakuin University, Ritsumeikan University, Doshisha University, Kansai University, Kindai University, Osaka City University, Osaka Prefecture University, Nihon University, Tokai University, Shizuoka University, Niigata University, Toyama University, Fukui University, Yamanashi University, Ibaraki University, Tochigi University, Gunma University, Saitama University, Chiba University, Tokyo Gakugei University, Tokyo University of Foreign Studies, Tokyo University of the Arts, Tokyo University of Marine Science and Technology, Tokyo University of Pharmacy and Life Sciences, Tokyo Medical and Dental University, Tokyo Institute of Psychiatry, National Center for Neurology and Psychiatry, National Institute of Advanced Industrial Science and Technology, National Institute of Information and Communications Technology, RIKEN, Japan Aerospace Exploration Agency, National Institute for Materials Science, National Institute for Environmental Studies, National Institute of Radiological Sciences, National Cancer Center, National Cerebral and Cardiovascular Center, National Center for Child Health and Development, National Center for Geriatrics and Gerontology, National Center for Global Health and Medicine, National Center for Neurology and Psychiatry, National Center for Psychiatry and Neurology, National Center for Tuberculosis and Leprosy Control, National Institute of Infectious Diseases, National Institute of Health Sciences, National Institute of Occupational Safety and Health, National Institute of Public Health, National Institute of Mental Health, National Institute of Neuroscience, National Institute of Genetics, National Institute for Basic Biology, National Institute for Physiological Sciences, National Institute for Fusion Science, National Institute for Materials Science, National Institute for Environmental Studies, National Institute of Radiological Sciences, National Cancer Center, National Cerebral and Cardiovascular Center, National Center for Child Health and Development, National Center for Geriatrics and Gerontology, National Center for Global Health and Medicine, National Center for Neurology and Psychiatry, National Center for Psychiatry and Neurology, National Center for Tuberculosis and Leprosy Control, National Institute of Infectious Diseases, National Institute of Health Sciences, National Institute of Occupational Safety and Health, National Institute of Public Health, National Institute of Mental Health, National Institute of Neuroscience, National Institute of Genetics, National Institute for Basic Biology, National Institute for Physiological Sciences, National Institute for Fusion Science, National Institute for Materials Science, National Institute for Environmental Studies, National Institute of Radiological Sciences, National Cancer Center, National Cerebral and Cardiovascular Center, National Center for Child Health and Development, National Center for Geriatrics and Gerontology, National Center for Global Health and Medicine, National Center for Neurology and Psychiatry, National Center for Psychiatry and Neurology, National Center for Tuberculosis and Leprosy Control, National Institute of Infectious Diseases, National Institute of Health Sciences, National Institute of Occupational Safety and Health, National Institute of Public Health, National Institute of Mental Health, National Institute of Neuroscience, National Institute of Genetics, National Institute for Basic Biology, National Institute for Physiological Sciences, National Institute for Fusion Science, National Institute for Materials Science, National Institute for Environmental Studies, National Institute of Radiological Sciences, National Cancer Center, National Cerebral and Cardiovascular Center, National Center for Child Health and Development, National Center for Geriatrics and Gerontology, National Center for Global Health and Medicine, National Center for Neurology and Psychiatry, National Center for Psychiatry and Neurology, National Center for Tuberculosis and Leprosy Control, National Institute of Infectious Diseases, National Institute of Health Sciences, National Institute of Occupational Safety and Health, National Institute of Public Health, National Institute of Mental Health, National Institute of Neuroscience, National Institute of Genetics, National Institute for Basic Biology, National Institute for Physiological Sciences, National Institute for Fusion Science, National Institute for Materials Science, National Institute for Environmental Studies, National Institute of Radiological Sciences, National Cancer Center, National Cerebral and Cardiovascular Center, National Center for Child Health and Development, National Center for Geriatrics and Gerontology, National Center for Global Health and Medicine, National Center for Neurology and Psychiatry, National Center for Psychiatry and Neurology, National Center for Tuberculosis and Leprosy Control, National Institute of Infectious Diseases, National Institute of Health Sciences, National Institute of Occupational Safety and Health, National Institute of Public Health, National Institute of Mental Health, National Institute of Neuroscience, National Institute of Genetics, National Institute for Basic Biology, National Institute for Physiological Sciences, National Institute for Fusion Science, National Institute for Materials Science, National Institute for Environmental Studies, National Institute of Radiological Sciences, National Cancer Center, National Cerebral and Cardiovascular Center, National Center for Child Health and Development, National Center for Geriatrics and Gerontology, National Center for Global Health and Medicine, National Center for Neurology and Psychiatry, National Center for Psychiatry and Neurology, National Center for Tuberculosis and Leprosy Control, National Institute of Infectious Diseases, National Institute of Health Sciences, National Institute of Occupational Safety and Health, National Institute of Public Health, National Institute of Mental Health

---


**ÊÄªÁªì**:
- [CycleVLA: Proactive Self-Correcting Vision-Language-Action Models via Subtask Backtracking and Minimum Bayes Risk Decoding](https://arxiv.org/abs/2601.02295)
  - Chenyang Ma, Guangyu Yang, Kai Lu, Shitong Xu, Bill Byrne, Niki Trigoni, Andrew Markham
  - Publish Date: 2026.01.05
  - Project Page: [CycleVLA](https://dannymcy.github.io/cyclevla/)
  - Task: Planning
  - SummaryÔºö
    - Introduces CycleVLA, a system that equips Vision-Language-Action models (VLAs) with proactive self-correction to anticipate and recover from failures before they fully manifest.
    - Integrates a progress-aware VLA, a VLM-based failure predictor/planner for subtask backtracking, and a test-time scaling strategy using Minimum Bayes Risk (MBR) decoding.
    - Demonstrates improved performance for both well-trained and under-trained VLAs, with MBR serving as an effective zero-shot test-time scaling strategy.

---
