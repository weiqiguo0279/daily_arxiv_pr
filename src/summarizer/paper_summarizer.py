"""
è®ºæ–‡æ€»ç»“å™¨

ä½¿ç”¨ LLM å¯¹ arXiv è®ºæ–‡è¿›è¡Œæ™ºèƒ½æ€»ç»“
"""
import logging
from typing import List, Dict, Any
from datetime import datetime
from pathlib import Path
from tqdm import tqdm

from src.utils import save_json, get_date_string, get_data_path
from .llm_factory import LLMClientFactory


class PaperSummarizer:
    """è®ºæ–‡æ€»ç»“å™¨"""
    
    # ç³»ç»Ÿæç¤ºè¯
    SYSTEM_PROMPT = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å­¦æœ¯è®ºæ–‡åˆ†æåŠ©æ‰‹ã€‚ä½ çš„ä»»åŠ¡æ˜¯é˜…è¯» arXiv è®ºæ–‡çš„æ ‡é¢˜å’Œæ‘˜è¦ï¼Œ
ç„¶åç”Ÿæˆä¸€ä¸ªç®€æ´ã€å‡†ç¡®çš„ä¸­æ–‡æ€»ç»“ã€‚

æ€»ç»“è¦æ±‚ï¼š
1. ç”¨ 2-3 å¥è¯æ¦‚æ‹¬è®ºæ–‡çš„æ ¸å¿ƒå†…å®¹
2. çªå‡ºè®ºæ–‡çš„ä¸»è¦åˆ›æ–°ç‚¹å’Œè´¡çŒ®
3. ä½¿ç”¨ä¸“ä¸šä½†æ˜“æ‡‚çš„è¯­è¨€
4. ä¿æŒå®¢è§‚å’Œå‡†ç¡®
5. å­—æ•°æ§åˆ¶åœ¨ 150-200 å­—ä»¥å†…
"""
    
    # ç”¨æˆ·æç¤ºè¯æ¨¡æ¿
    USER_PROMPT_TEMPLATE = """è¯·æ€»ç»“ä»¥ä¸‹è®ºæ–‡ï¼š

æ ‡é¢˜ï¼š{title}

ä½œè€…ï¼š{authors}

æ‘˜è¦ï¼š
{abstract}

è¯·ç”¨ä¸­æ–‡ç»™å‡ºç®€æ´çš„æ€»ç»“ï¼ˆ150-200å­—ï¼‰ï¼š"""
    
    def __init__(self, config: Dict[str, Any]):
        """åˆå§‹åŒ–
        
        Args:
            config: é…ç½®å­—å…¸
        """
        self.config = config
        self.logger = logging.getLogger('daily_arxiv.summarizer')
        
        # åˆ›å»º LLM å®¢æˆ·ç«¯
        try:
            self.llm_client = LLMClientFactory.create_client(config)
            self.logger.info(f"ä½¿ç”¨ LLM: {self.llm_client.get_provider_name()}")
        except Exception as e:
            self.logger.error(f"åˆå§‹åŒ– LLM å®¢æˆ·ç«¯å¤±è´¥: {str(e)}")
            raise
    
    def summarize_paper(self, paper: Dict[str, Any]) -> Dict[str, Any]:
        """æ€»ç»“å•ç¯‡è®ºæ–‡
        
        Args:
            paper: è®ºæ–‡ä¿¡æ¯å­—å…¸
            
        Returns:
            åŒ…å«æ€»ç»“çš„è®ºæ–‡ä¿¡æ¯
        """
        try:
            # æ„å»ºæç¤ºè¯
            authors_str = ", ".join(paper['authors'][:5])
            if len(paper['authors']) > 5:
                authors_str += " et al."
            
            prompt = self.USER_PROMPT_TEMPLATE.format(
                title=paper['title'],
                authors=authors_str,
                abstract=paper['abstract']
            )
            
            # ç”Ÿæˆæ€»ç»“
            summary = self.llm_client.generate(
                prompt=prompt,
                system_prompt=self.SYSTEM_PROMPT
            )
            
            # æ·»åŠ æ€»ç»“åˆ°è®ºæ–‡ä¿¡æ¯
            paper_with_summary = paper.copy()
            paper_with_summary['summary'] = summary
            paper_with_summary['summarized_at'] = datetime.now().isoformat()
            
            return paper_with_summary
            
        except Exception as e:
            self.logger.error(f"æ€»ç»“è®ºæ–‡å¤±è´¥ [{paper.get('title', 'Unknown')}]: {str(e)}")
            paper_with_summary = paper.copy()
            paper_with_summary['summary'] = f"æ€»ç»“ç”Ÿæˆå¤±è´¥: {str(e)}"
            paper_with_summary['summary_error'] = True
            return paper_with_summary
    
    def summarize_papers(self, papers: List[Dict[str, Any]], 
                        show_progress: bool = True) -> List[Dict[str, Any]]:
        """æ‰¹é‡æ€»ç»“è®ºæ–‡
        
        Args:
            papers: è®ºæ–‡åˆ—è¡¨
            show_progress: æ˜¯å¦æ˜¾ç¤ºè¿›åº¦æ¡
            
        Returns:
            åŒ…å«æ€»ç»“çš„è®ºæ–‡åˆ—è¡¨
        """
        if not papers:
            self.logger.warning("æ²¡æœ‰è®ºæ–‡éœ€è¦æ€»ç»“")
            return []
        
        self.logger.info("=" * 60)
        self.logger.info(f"å¼€å§‹æ€»ç»“ {len(papers)} ç¯‡è®ºæ–‡")
        self.logger.info(f"ä½¿ç”¨æ¨¡å‹: {self.llm_client.model}")
        self.logger.info("=" * 60)
        
        summarized_papers = []
        
        # ä½¿ç”¨è¿›åº¦æ¡
        iterator = tqdm(papers, desc="æ€»ç»“è®ºæ–‡") if show_progress else papers
        
        for i, paper in enumerate(iterator, 1):
            try:
                self.logger.info(f"\n[{i}/{len(papers)}] æ­£åœ¨æ€»ç»“: {paper['title'][:50]}...")
                
                summarized_paper = self.summarize_paper(paper)
                summarized_papers.append(summarized_paper)
                
                if not summarized_paper.get('summary_error'):
                    self.logger.info(f"âœ“ æ€»ç»“å®Œæˆ")
                    if not show_progress:
                        # å¦‚æœæ²¡æœ‰è¿›åº¦æ¡ï¼Œæ˜¾ç¤ºæ€»ç»“é¢„è§ˆ
                        summary_preview = summarized_paper['summary'][:100]
                        self.logger.info(f"  æ€»ç»“é¢„è§ˆ: {summary_preview}...")
                else:
                    self.logger.warning(f"âš  æ€»ç»“å¤±è´¥")
                    
            except Exception as e:
                self.logger.error(f"å¤„ç†è®ºæ–‡æ—¶å‡ºé”™: {str(e)}")
                paper_with_error = paper.copy()
                paper_with_error['summary'] = f"å¤„ç†å¤±è´¥: {str(e)}"
                paper_with_error['summary_error'] = True
                summarized_papers.append(paper_with_error)
        
        # ç»Ÿè®¡
        success_count = sum(1 for p in summarized_papers if not p.get('summary_error'))
        fail_count = len(summarized_papers) - success_count
        
        self.logger.info("\n" + "=" * 60)
        self.logger.info(f"âœ… æ€»ç»“å®Œæˆ: {success_count} ç¯‡æˆåŠŸ, {fail_count} ç¯‡å¤±è´¥")
        self.logger.info("=" * 60)
        
        # ä¿å­˜ç»“æœ
        self._save_summaries(summarized_papers)
        
        return summarized_papers
    
    def _save_summaries(self, papers: List[Dict[str, Any]]):
        """ä¿å­˜æ€»ç»“ç»“æœ
        
        Args:
            papers: åŒ…å«æ€»ç»“çš„è®ºæ–‡åˆ—è¡¨
        """
        if not papers:
            return
        
        # è·å–å­˜å‚¨è·¯å¾„
        data_path = get_data_path(self.config, 'summaries')
        Path(data_path).mkdir(parents=True, exist_ok=True)
        
        # æŒ‰æ—¥æœŸä¿å­˜
        date_str = get_date_string()
        filepath = f"{data_path}/summaries_{date_str}.json"
        
        # ä¿å­˜æ•°æ®
        save_json(papers, filepath)
        self.logger.info(f"ğŸ’¾ æ€»ç»“æ•°æ®å·²ä¿å­˜åˆ°: {filepath}")
        
        # åŒæ—¶ä¿å­˜ä¸€ä»½åˆ° latest.json
        latest_filepath = f"{data_path}/latest.json"
        save_json({
            'date': date_str,
            'count': len(papers),
            'papers': papers,
            'llm_provider': self.llm_client.get_provider_name(),
            'llm_model': self.llm_client.model,
        }, latest_filepath)
        self.logger.info(f"ğŸ’¾ æœ€æ–°æ€»ç»“å·²ä¿å­˜åˆ°: {latest_filepath}")
    
    def generate_daily_report(self, papers: List[Dict[str, Any]]) -> str:
        """ç”Ÿæˆæ¯æ—¥æŠ¥å‘Š
        
        Args:
            papers: åŒ…å«æ€»ç»“çš„è®ºæ–‡åˆ—è¡¨
            
        Returns:
            æŠ¥å‘Šæ–‡æœ¬
        """
        if not papers:
            return "ä»Šæ—¥æ²¡æœ‰è®ºæ–‡ã€‚"
        
        report_parts = []
        report_parts.append(f"# ğŸ“š æ¯æ—¥ arXiv è®ºæ–‡æ€»ç»“")
        report_parts.append(f"\n**æ—¥æœŸ**: {get_date_string()}")
        report_parts.append(f"**è®ºæ–‡æ•°é‡**: {len(papers)} ç¯‡")
        report_parts.append(f"**LLM**: {self.llm_client.get_provider_name()} ({self.llm_client.model})")
        report_parts.append("\n---\n")
        
        for i, paper in enumerate(papers, 1):
            report_parts.append(f"\n## {i}. {paper['title']}")
            report_parts.append(f"\n**ä½œè€…**: {', '.join(paper['authors'][:3])}" + 
                              (" et al." if len(paper['authors']) > 3 else ""))
            report_parts.append(f"\n**ç±»åˆ«**: {', '.join(paper['categories'][:3])}")
            report_parts.append(f"\n**é“¾æ¥**: [{paper['id']}]({paper['pdf_url']})")
            
            if 'summary' in paper and not paper.get('summary_error'):
                report_parts.append(f"\n**æ€»ç»“**:\n{paper['summary']}")
            else:
                report_parts.append(f"\n**æ€»ç»“**: æš‚æ— ")
            
            report_parts.append("\n---\n")
        
        return "\n".join(report_parts)


def main():
    """æµ‹è¯•å‡½æ•°"""
    from src.utils import load_config, load_env, setup_logging, load_json
    
    load_env()
    config = load_config()
    logger = setup_logging(config)
    
    # åŠ è½½å·²çˆ¬å–çš„è®ºæ–‡
    data_path = get_data_path(config, 'papers')
    latest_file = f"{data_path}/latest.json"
    data = load_json(latest_file)
    
    if not data or not data.get('papers'):
        logger.error("æ²¡æœ‰æ‰¾åˆ°è®ºæ–‡æ•°æ®ï¼Œè¯·å…ˆè¿è¡Œè®ºæ–‡çˆ¬å–")
        return
    
    papers = data['papers'][:3]  # åªæµ‹è¯•å‰3ç¯‡
    
    # åˆ›å»ºæ€»ç»“å™¨
    summarizer = PaperSummarizer(config)
    
    # æ€»ç»“è®ºæ–‡
    summarized_papers = summarizer.summarize_papers(papers)
    
    # ç”ŸæˆæŠ¥å‘Š
    report = summarizer.generate_daily_report(summarized_papers)
    print("\n" + report)


if __name__ == "__main__":
    main()
